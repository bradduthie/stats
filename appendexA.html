<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>A Answers to chapter exercises | Fundamental statistical concepts and techniques in the biological and environmental sciences: With jamovi</title>
  <meta name="description" content="This is an introductory statistics textbook for students in the biological and environmental sciences with examples using jamovi statistical software." />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="A Answers to chapter exercises | Fundamental statistical concepts and techniques in the biological and environmental sciences: With jamovi" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is an introductory statistics textbook for students in the biological and environmental sciences with examples using jamovi statistical software." />
  <meta name="github-repo" content="bradduthie/statistics_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Answers to chapter exercises | Fundamental statistical concepts and techniques in the biological and environmental sciences: With jamovi" />
  
  <meta name="twitter:description" content="This is an introductory statistics textbook for students in the biological and environmental sciences with examples using jamovi statistical software." />
  

<meta name="author" content="A. Bradley Duthie" />


<meta name="date" content="2024-03-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chapter_35.html"/>
<link rel="next" href="uncertainty_derivation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { font-weight: bold; } /* Alert */
code span.an { font-style: italic; } /* Annotation */
code span.cf { font-weight: bold; } /* ControlFlow */
code span.co { font-style: italic; } /* Comment */
code span.cv { font-style: italic; } /* CommentVar */
code span.do { font-style: italic; } /* Documentation */
code span.dt { text-decoration: underline; } /* DataType */
code span.er { font-weight: bold; } /* Error */
code span.in { font-style: italic; } /* Information */
code span.kw { font-weight: bold; } /* Keyword */
code span.pp { font-weight: bold; } /* Preprocessor */
code span.wa { font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics with jamovi</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure"><i class="fa fa-check"></i>How this book is structured</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#datasets"><i class="fa fa-check"></i>Datasets used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#author"><i class="fa fa-check"></i>About the author</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chapter_1.html"><a href="Chapter_1.html"><i class="fa fa-check"></i><b>1</b> Background mathematics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="Chapter_1.html"><a href="Chapter_1.html#numbers-and-operations"><i class="fa fa-check"></i><b>1.1</b> Numbers and operations</a></li>
<li class="chapter" data-level="1.2" data-path="Chapter_1.html"><a href="Chapter_1.html#logarithms"><i class="fa fa-check"></i><b>1.2</b> Logarithms</a></li>
<li class="chapter" data-level="1.3" data-path="Chapter_1.html"><a href="Chapter_1.html#order-of-operations"><i class="fa fa-check"></i><b>1.3</b> Order of operations</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chapter_2.html"><a href="Chapter_2.html"><i class="fa fa-check"></i><b>2</b> Data organisation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="Chapter_2.html"><a href="Chapter_2.html#tidy-data"><i class="fa fa-check"></i><b>2.1</b> Tidy data</a></li>
<li class="chapter" data-level="2.2" data-path="Chapter_2.html"><a href="Chapter_2.html#data-files"><i class="fa fa-check"></i><b>2.2</b> Data files</a></li>
<li class="chapter" data-level="2.3" data-path="Chapter_2.html"><a href="Chapter_2.html#managing-data-files"><i class="fa fa-check"></i><b>2.3</b> Managing data files</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chapter_3.html"><a href="Chapter_3.html"><i class="fa fa-check"></i><b>3</b> <em>Practical</em>. Preparing data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-1-transferring-data-to-a-spreadsheet"><i class="fa fa-check"></i><b>3.1</b> Exercise 1: Transferring data to a spreadsheet</a></li>
<li class="chapter" data-level="3.2" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-2-making-spreadsheet-data-tidy"><i class="fa fa-check"></i><b>3.2</b> Exercise 2: Making spreadsheet data tidy</a></li>
<li class="chapter" data-level="3.3" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-3-making-data-tidy-again"><i class="fa fa-check"></i><b>3.3</b> Exercise 3: Making data tidy again</a></li>
<li class="chapter" data-level="3.4" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-4-tidy-data-and-spreadsheet-calculations"><i class="fa fa-check"></i><b>3.4</b> Exercise 4: Tidy data and spreadsheet calculations</a></li>
<li class="chapter" data-level="3.5" data-path="Chapter_3.html"><a href="Chapter_3.html#summary"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chapter_4.html"><a href="Chapter_4.html"><i class="fa fa-check"></i><b>4</b> Populations and samples</a></li>
<li class="chapter" data-level="5" data-path="Chapter_5.html"><a href="Chapter_5.html"><i class="fa fa-check"></i><b>5</b> Types of variables</a></li>
<li class="chapter" data-level="6" data-path="Chapter_6.html"><a href="Chapter_6.html"><i class="fa fa-check"></i><b>6</b> Accuracy, precision, and units</a>
<ul>
<li class="chapter" data-level="6.1" data-path="Chapter_6.html"><a href="Chapter_6.html#accuracy"><i class="fa fa-check"></i><b>6.1</b> Accuracy</a></li>
<li class="chapter" data-level="6.2" data-path="Chapter_6.html"><a href="Chapter_6.html#precision"><i class="fa fa-check"></i><b>6.2</b> Precision</a></li>
<li class="chapter" data-level="6.3" data-path="Chapter_6.html"><a href="Chapter_6.html#systems-of-units"><i class="fa fa-check"></i><b>6.3</b> Systems of units</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chapter_7.html"><a href="Chapter_7.html"><i class="fa fa-check"></i><b>7</b> Uncertainty propagation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="Chapter_7.html"><a href="Chapter_7.html#adding-or-subtracting-errors"><i class="fa fa-check"></i><b>7.1</b> Adding or subtracting errors</a></li>
<li class="chapter" data-level="7.2" data-path="Chapter_7.html"><a href="Chapter_7.html#multiplying-or-dividing-errors"><i class="fa fa-check"></i><b>7.2</b> Multiplying or dividing errors</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chapter_8.html"><a href="Chapter_8.html"><i class="fa fa-check"></i><b>8</b> <em>Practical</em>. Introduction to jamovi</a>
<ul>
<li class="chapter" data-level="8.1" data-path="Chapter_8.html"><a href="Chapter_8.html#summary_statistics_02"><i class="fa fa-check"></i><b>8.1</b> Exercise for summary statistics</a></li>
<li class="chapter" data-level="8.2" data-path="Chapter_8.html"><a href="Chapter_8.html#transforming_variables_02"><i class="fa fa-check"></i><b>8.2</b> Exercise on transforming variables</a></li>
<li class="chapter" data-level="8.3" data-path="Chapter_8.html"><a href="Chapter_8.html#computing_variables_02"><i class="fa fa-check"></i><b>8.3</b> Exercise on computing variables</a></li>
<li class="chapter" data-level="8.4" data-path="Chapter_8.html"><a href="Chapter_8.html#summary-1"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chapter_9.html"><a href="Chapter_9.html"><i class="fa fa-check"></i><b>9</b> Decimal places, significant figures, and rounding</a>
<ul>
<li class="chapter" data-level="9.1" data-path="Chapter_9.html"><a href="Chapter_9.html#decimal-places-and-significant-figures"><i class="fa fa-check"></i><b>9.1</b> Decimal places and significant figures</a></li>
<li class="chapter" data-level="9.2" data-path="Chapter_9.html"><a href="Chapter_9.html#rounding"><i class="fa fa-check"></i><b>9.2</b> Rounding</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chapter_10.html"><a href="Chapter_10.html"><i class="fa fa-check"></i><b>10</b> Graphs</a>
<ul>
<li class="chapter" data-level="10.1" data-path="Chapter_10.html"><a href="Chapter_10.html#histograms"><i class="fa fa-check"></i><b>10.1</b> Histograms</a></li>
<li class="chapter" data-level="10.2" data-path="Chapter_10.html"><a href="Chapter_10.html#barplots-and-pie-charts"><i class="fa fa-check"></i><b>10.2</b> Barplots and pie charts</a></li>
<li class="chapter" data-level="10.3" data-path="Chapter_10.html"><a href="Chapter_10.html#box-whisker-plots"><i class="fa fa-check"></i><b>10.3</b> Box-whisker plots</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chapter_11.html"><a href="Chapter_11.html"><i class="fa fa-check"></i><b>11</b> Measures of central tendency</a>
<ul>
<li class="chapter" data-level="11.1" data-path="Chapter_11.html"><a href="Chapter_11.html#the-mean"><i class="fa fa-check"></i><b>11.1</b> The mean</a></li>
<li class="chapter" data-level="11.2" data-path="Chapter_11.html"><a href="Chapter_11.html#the-mode"><i class="fa fa-check"></i><b>11.2</b> The mode</a></li>
<li class="chapter" data-level="11.3" data-path="Chapter_11.html"><a href="Chapter_11.html#the-median-and-quantiles"><i class="fa fa-check"></i><b>11.3</b> The median and quantiles</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chapter_12.html"><a href="Chapter_12.html"><i class="fa fa-check"></i><b>12</b> Measures of spread</a>
<ul>
<li class="chapter" data-level="12.1" data-path="Chapter_12.html"><a href="Chapter_12.html#the-range"><i class="fa fa-check"></i><b>12.1</b> The range</a></li>
<li class="chapter" data-level="12.2" data-path="Chapter_12.html"><a href="Chapter_12.html#the-inter-quartile-range"><i class="fa fa-check"></i><b>12.2</b> The inter-quartile range</a></li>
<li class="chapter" data-level="12.3" data-path="Chapter_12.html"><a href="Chapter_12.html#the-variance"><i class="fa fa-check"></i><b>12.3</b> The variance</a></li>
<li class="chapter" data-level="12.4" data-path="Chapter_12.html"><a href="Chapter_12.html#the-standard-deviation"><i class="fa fa-check"></i><b>12.4</b> The standard deviation</a></li>
<li class="chapter" data-level="12.5" data-path="Chapter_12.html"><a href="Chapter_12.html#the-coefficient-of-variation"><i class="fa fa-check"></i><b>12.5</b> The coefficient of variation</a></li>
<li class="chapter" data-level="12.6" data-path="Chapter_12.html"><a href="Chapter_12.html#the-standard-error"><i class="fa fa-check"></i><b>12.6</b> The standard error</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chapter_13.html"><a href="Chapter_13.html"><i class="fa fa-check"></i><b>13</b> Skew and Kurtosis</a>
<ul>
<li class="chapter" data-level="13.1" data-path="Chapter_13.html"><a href="Chapter_13.html#skew"><i class="fa fa-check"></i><b>13.1</b> Skew</a></li>
<li class="chapter" data-level="13.2" data-path="Chapter_13.html"><a href="Chapter_13.html#kurtosis"><i class="fa fa-check"></i><b>13.2</b> Kurtosis</a></li>
<li class="chapter" data-level="13.3" data-path="Chapter_13.html"><a href="Chapter_13.html#moments"><i class="fa fa-check"></i><b>13.3</b> Moments</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chapter_14.html"><a href="Chapter_14.html"><i class="fa fa-check"></i><b>14</b> <em>Practical</em>. Plotting and statistical summaries in jamovi</a>
<ul>
<li class="chapter" data-level="14.1" data-path="Chapter_14.html"><a href="Chapter_14.html#reorganise-the-dataset-into-a-tidy-format"><i class="fa fa-check"></i><b>14.1</b> Reorganise the dataset into a tidy format</a></li>
<li class="chapter" data-level="14.2" data-path="Chapter_14.html"><a href="Chapter_14.html#histograms-and-box-whisker-plots"><i class="fa fa-check"></i><b>14.2</b> Histograms and box-whisker plots</a></li>
<li class="chapter" data-level="14.3" data-path="Chapter_14.html"><a href="Chapter_14.html#calculate-summary-statistics"><i class="fa fa-check"></i><b>14.3</b> Calculate summary statistics</a></li>
<li class="chapter" data-level="14.4" data-path="Chapter_14.html"><a href="Chapter_14.html#reporting-decimals-and-significant-figures"><i class="fa fa-check"></i><b>14.4</b> Reporting decimals and significant figures</a></li>
<li class="chapter" data-level="14.5" data-path="Chapter_14.html"><a href="Chapter_14.html#comparing-across-sites"><i class="fa fa-check"></i><b>14.5</b> Comparing across sites</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="Chapter_15.html"><a href="Chapter_15.html"><i class="fa fa-check"></i><b>15</b> Introduction to probability models</a>
<ul>
<li class="chapter" data-level="15.1" data-path="Chapter_15.html"><a href="Chapter_15.html#an-instructive-example"><i class="fa fa-check"></i><b>15.1</b> An instructive example</a></li>
<li class="chapter" data-level="15.2" data-path="Chapter_15.html"><a href="Chapter_15.html#biological-applications"><i class="fa fa-check"></i><b>15.2</b> Biological applications</a></li>
<li class="chapter" data-level="15.3" data-path="Chapter_15.html"><a href="Chapter_15.html#sampling-with-and-without-replacement"><i class="fa fa-check"></i><b>15.3</b> Sampling with and without replacement</a></li>
<li class="chapter" data-level="15.4" data-path="Chapter_15.html"><a href="Chapter_15.html#probability-distributions"><i class="fa fa-check"></i><b>15.4</b> Probability distributions</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="Chapter_15.html"><a href="Chapter_15.html#binomial-distribution"><i class="fa fa-check"></i><b>15.4.1</b> Binomial distribution</a></li>
<li class="chapter" data-level="15.4.2" data-path="Chapter_15.html"><a href="Chapter_15.html#poisson-distribution"><i class="fa fa-check"></i><b>15.4.2</b> Poisson distribution</a></li>
<li class="chapter" data-level="15.4.3" data-path="Chapter_15.html"><a href="Chapter_15.html#uniform-distribution"><i class="fa fa-check"></i><b>15.4.3</b> Uniform distribution</a></li>
<li class="chapter" data-level="15.4.4" data-path="Chapter_15.html"><a href="Chapter_15.html#normal-distribution"><i class="fa fa-check"></i><b>15.4.4</b> Normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="Chapter_15.html"><a href="Chapter_15.html#summary-2"><i class="fa fa-check"></i><b>15.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="Chapter_16.html"><a href="Chapter_16.html"><i class="fa fa-check"></i><b>16</b> The Central Limit Theorem (CLT)</a>
<ul>
<li class="chapter" data-level="16.1" data-path="Chapter_16.html"><a href="Chapter_16.html#the-distribution-of-means-is-normal"><i class="fa fa-check"></i><b>16.1</b> The distribution of means is normal</a></li>
<li class="chapter" data-level="16.2" data-path="Chapter_16.html"><a href="Chapter_16.html#probability-and-z-scores"><i class="fa fa-check"></i><b>16.2</b> Probability and z-scores</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="Chapter_17.html"><a href="Chapter_17.html"><i class="fa fa-check"></i><b>17</b> <em>Practical</em>. Probability and simulation</a>
<ul>
<li class="chapter" data-level="17.1" data-path="Chapter_17.html"><a href="Chapter_17.html#probabilities-from-a-dataset"><i class="fa fa-check"></i><b>17.1</b> Probabilities from a dataset</a></li>
<li class="chapter" data-level="17.2" data-path="Chapter_17.html"><a href="Chapter_17.html#probabilities-from-a-normal-distribution"><i class="fa fa-check"></i><b>17.2</b> Probabilities from a normal distribution</a></li>
<li class="chapter" data-level="17.3" data-path="Chapter_17.html"><a href="Chapter_17.html#central-limit-theorem"><i class="fa fa-check"></i><b>17.3</b> Central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="Chapter_18.html"><a href="Chapter_18.html"><i class="fa fa-check"></i><b>18</b> Confidence intervals (CIs)</a>
<ul>
<li class="chapter" data-level="18.1" data-path="Chapter_18.html"><a href="Chapter_18.html#normal-distribution-cis"><i class="fa fa-check"></i><b>18.1</b> Normal distribution CIs</a></li>
<li class="chapter" data-level="18.2" data-path="Chapter_18.html"><a href="Chapter_18.html#binomial-distribution-cis"><i class="fa fa-check"></i><b>18.2</b> Binomial distribution CIs</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="Chapter_19.html"><a href="Chapter_19.html"><i class="fa fa-check"></i><b>19</b> The t-interval</a></li>
<li class="chapter" data-level="20" data-path="Chapter_20.html"><a href="Chapter_20.html"><i class="fa fa-check"></i><b>20</b> <em>Practical</em>. z- and t- intervals</a>
<ul>
<li class="chapter" data-level="20.1" data-path="Chapter_20.html"><a href="Chapter_20.html#confidence-intervals-with-distraction"><i class="fa fa-check"></i><b>20.1</b> Confidence intervals with distrACTION</a></li>
<li class="chapter" data-level="20.2" data-path="Chapter_20.html"><a href="Chapter_20.html#confidence-intervals-from-z--and-t-scores"><i class="fa fa-check"></i><b>20.2</b> Confidence intervals from z- and t-scores</a></li>
<li class="chapter" data-level="20.3" data-path="Chapter_20.html"><a href="Chapter_20.html#confidence-intervals-for-different-sample-sizes-t--and-z-"><i class="fa fa-check"></i><b>20.3</b> Confidence intervals for different sample sizes (t- and z-)</a></li>
<li class="chapter" data-level="20.4" data-path="Chapter_20.html"><a href="Chapter_20.html#proportion-confidence-intervals"><i class="fa fa-check"></i><b>20.4</b> Proportion confidence intervals</a></li>
<li class="chapter" data-level="20.5" data-path="Chapter_20.html"><a href="Chapter_20.html#another-proportion-confidence-interval"><i class="fa fa-check"></i><b>20.5</b> Another proportion confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="Chapter_21.html"><a href="Chapter_21.html"><i class="fa fa-check"></i><b>21</b> What is hypothesis testing?</a>
<ul>
<li class="chapter" data-level="21.1" data-path="Chapter_21.html"><a href="Chapter_21.html#how-ridiculous-is-our-hypothesis"><i class="fa fa-check"></i><b>21.1</b> How ridiculous is our hypothesis?</a></li>
<li class="chapter" data-level="21.2" data-path="Chapter_21.html"><a href="Chapter_21.html#statistical-hypothesis-testing"><i class="fa fa-check"></i><b>21.2</b> Statistical hypothesis testing</a></li>
<li class="chapter" data-level="21.3" data-path="Chapter_21.html"><a href="Chapter_21.html#p-values-false-positives-and-power"><i class="fa fa-check"></i><b>21.3</b> P-values, false positives, and power</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="Chapter_22.html"><a href="Chapter_22.html"><i class="fa fa-check"></i><b>22</b> The t-test</a>
<ul>
<li class="chapter" data-level="22.1" data-path="Chapter_22.html"><a href="Chapter_22.html#one-sample-t-test"><i class="fa fa-check"></i><b>22.1</b> One sample t-test</a></li>
<li class="chapter" data-level="22.2" data-path="Chapter_22.html"><a href="Chapter_22.html#independent-samples-t-test"><i class="fa fa-check"></i><b>22.2</b> Independent samples t-test</a></li>
<li class="chapter" data-level="22.3" data-path="Chapter_22.html"><a href="Chapter_22.html#paired-samples-t-test"><i class="fa fa-check"></i><b>22.3</b> Paired samples t-test</a></li>
<li class="chapter" data-level="22.4" data-path="Chapter_22.html"><a href="Chapter_22.html#assumptions-of-t-tests"><i class="fa fa-check"></i><b>22.4</b> Assumptions of t-tests</a></li>
<li class="chapter" data-level="22.5" data-path="Chapter_22.html"><a href="Chapter_22.html#non-parametric-alternatives"><i class="fa fa-check"></i><b>22.5</b> Non-parametric alternatives</a>
<ul>
<li class="chapter" data-level="22.5.1" data-path="Chapter_22.html"><a href="Chapter_22.html#wilcoxon-test"><i class="fa fa-check"></i><b>22.5.1</b> Wilcoxon test</a></li>
<li class="chapter" data-level="22.5.2" data-path="Chapter_22.html"><a href="Chapter_22.html#mann-whitney-u-test"><i class="fa fa-check"></i><b>22.5.2</b> Mann-Whitney U test</a></li>
</ul></li>
<li class="chapter" data-level="22.6" data-path="Chapter_22.html"><a href="Chapter_22.html#summary-3"><i class="fa fa-check"></i><b>22.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="Chapter_23.html"><a href="Chapter_23.html"><i class="fa fa-check"></i><b>23</b> <em>Practical</em>. Hypothesis testing and t-tests</a>
<ul>
<li class="chapter" data-level="23.1" data-path="Chapter_23.html"><a href="Chapter_23.html#exercise-on-a-simple-one-sample-t-test"><i class="fa fa-check"></i><b>23.1</b> Exercise on a simple one sample t-test</a></li>
<li class="chapter" data-level="23.2" data-path="Chapter_23.html"><a href="Chapter_23.html#exercise-on-a-paired-t-test"><i class="fa fa-check"></i><b>23.2</b> Exercise on a paired t-test</a></li>
<li class="chapter" data-level="23.3" data-path="Chapter_23.html"><a href="Chapter_23.html#wilcoxon-test-1"><i class="fa fa-check"></i><b>23.3</b> Wilcoxon test</a></li>
<li class="chapter" data-level="23.4" data-path="Chapter_23.html"><a href="Chapter_23.html#independent-samples-t-test-1"><i class="fa fa-check"></i><b>23.4</b> Independent samples t-test</a></li>
<li class="chapter" data-level="23.5" data-path="Chapter_23.html"><a href="Chapter_23.html#mann-whitney-u-test-1"><i class="fa fa-check"></i><b>23.5</b> Mann-Whitney U Test</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="Chapter_24.html"><a href="Chapter_24.html"><i class="fa fa-check"></i><b>24</b> Analysis of variance</a>
<ul>
<li class="chapter" data-level="24.1" data-path="Chapter_24.html"><a href="Chapter_24.html#the-f-distribution"><i class="fa fa-check"></i><b>24.1</b> The F-distribution</a></li>
<li class="chapter" data-level="24.2" data-path="Chapter_24.html"><a href="Chapter_24.html#one-way-anova"><i class="fa fa-check"></i><b>24.2</b> One-way ANOVA</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="Chapter_24.html"><a href="Chapter_24.html#anova-mean-variance-among-groups"><i class="fa fa-check"></i><b>24.2.1</b> ANOVA mean variance among groups</a></li>
<li class="chapter" data-level="24.2.2" data-path="Chapter_24.html"><a href="Chapter_24.html#anova-mean-variance-within-groups"><i class="fa fa-check"></i><b>24.2.2</b> ANOVA mean variance within groups</a></li>
<li class="chapter" data-level="24.2.3" data-path="Chapter_24.html"><a href="Chapter_24.html#anova-f-statistic-calculation"><i class="fa fa-check"></i><b>24.2.3</b> ANOVA F-statistic calculation</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="Chapter_24.html"><a href="Chapter_24.html#assumptions-of-anova"><i class="fa fa-check"></i><b>24.3</b> Assumptions of ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="Chapter_25.html"><a href="Chapter_25.html"><i class="fa fa-check"></i><b>25</b> Multiple comparisons</a></li>
<li class="chapter" data-level="26" data-path="Chapter_26.html"><a href="Chapter_26.html"><i class="fa fa-check"></i><b>26</b> Kruskall-Wallis H test</a></li>
<li class="chapter" data-level="27" data-path="Chapter_27.html"><a href="Chapter_27.html"><i class="fa fa-check"></i><b>27</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="28" data-path="Chapter_28.html"><a href="Chapter_28.html"><i class="fa fa-check"></i><b>28</b> <em>Practical</em>. ANOVA and associated tests</a>
<ul>
<li class="chapter" data-level="28.1" data-path="Chapter_28.html"><a href="Chapter_28.html#one-way-anova-site"><i class="fa fa-check"></i><b>28.1</b> One-way ANOVA (site)</a></li>
<li class="chapter" data-level="28.2" data-path="Chapter_28.html"><a href="Chapter_28.html#one-way-anova-profile"><i class="fa fa-check"></i><b>28.2</b> One-way ANOVA (profile)</a></li>
<li class="chapter" data-level="28.3" data-path="Chapter_28.html"><a href="Chapter_28.html#multiple-comparisons"><i class="fa fa-check"></i><b>28.3</b> Multiple comparisons</a></li>
<li class="chapter" data-level="28.4" data-path="Chapter_28.html"><a href="Chapter_28.html#kruskall-wallis-h-test"><i class="fa fa-check"></i><b>28.4</b> Kruskall-Wallis H test</a></li>
<li class="chapter" data-level="28.5" data-path="Chapter_28.html"><a href="Chapter_28.html#two-way-anova"><i class="fa fa-check"></i><b>28.5</b> Two-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="Chapter_29.html"><a href="Chapter_29.html"><i class="fa fa-check"></i><b>29</b> Frequency and count data</a>
<ul>
<li class="chapter" data-level="29.1" data-path="Chapter_29.html"><a href="Chapter_29.html#the-chi-square-distribution"><i class="fa fa-check"></i><b>29.1</b> The Chi-square distribution</a></li>
<li class="chapter" data-level="29.2" data-path="Chapter_29.html"><a href="Chapter_29.html#chi-square-goodness-of-fit"><i class="fa fa-check"></i><b>29.2</b> Chi-square goodness of fit</a></li>
<li class="chapter" data-level="29.3" data-path="Chapter_29.html"><a href="Chapter_29.html#chi-square-test-of-association"><i class="fa fa-check"></i><b>29.3</b> Chi-square test of association</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="Chapter_30.html"><a href="Chapter_30.html"><i class="fa fa-check"></i><b>30</b> Correlation</a>
<ul>
<li class="chapter" data-level="30.1" data-path="Chapter_30.html"><a href="Chapter_30.html#scatterplots"><i class="fa fa-check"></i><b>30.1</b> Scatterplots</a></li>
<li class="chapter" data-level="30.2" data-path="Chapter_30.html"><a href="Chapter_30.html#the-correlation-coefficient"><i class="fa fa-check"></i><b>30.2</b> The correlation coefficient</a>
<ul>
<li class="chapter" data-level="30.2.1" data-path="Chapter_30.html"><a href="Chapter_30.html#pearson-product-moment-correlation-coefficient"><i class="fa fa-check"></i><b>30.2.1</b> Pearson product moment correlation coefficient</a></li>
<li class="chapter" data-level="30.2.2" data-path="Chapter_30.html"><a href="Chapter_30.html#spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>30.2.2</b> Spearman’s rank correlation coefficient</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="Chapter_30.html"><a href="Chapter_30.html#correlation-hypothesis-testing"><i class="fa fa-check"></i><b>30.3</b> Correlation hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="Chapter_31.html"><a href="Chapter_31.html"><i class="fa fa-check"></i><b>31</b> <em>Practical</em>. Analysis of counts and correlations</a>
<ul>
<li class="chapter" data-level="31.1" data-path="Chapter_31.html"><a href="Chapter_31.html#survival-goodness-of-fit"><i class="fa fa-check"></i><b>31.1</b> Survival goodness of fit</a></li>
<li class="chapter" data-level="31.2" data-path="Chapter_31.html"><a href="Chapter_31.html#colony-goodness-of-fit"><i class="fa fa-check"></i><b>31.2</b> Colony goodness of fit</a></li>
<li class="chapter" data-level="31.3" data-path="Chapter_31.html"><a href="Chapter_31.html#chi-square-test-of-association-1"><i class="fa fa-check"></i><b>31.3</b> Chi-Square test of association</a></li>
<li class="chapter" data-level="31.4" data-path="Chapter_31.html"><a href="Chapter_31.html#pearson-product-moment-correlation-test"><i class="fa fa-check"></i><b>31.4</b> Pearson product moment correlation test</a></li>
<li class="chapter" data-level="31.5" data-path="Chapter_31.html"><a href="Chapter_31.html#spearmans-rank-correlation-test"><i class="fa fa-check"></i><b>31.5</b> Spearman’s rank correlation test</a></li>
<li class="chapter" data-level="31.6" data-path="Chapter_31.html"><a href="Chapter_31.html#untidy-goodness-of-fit"><i class="fa fa-check"></i><b>31.6</b> Untidy goodness of fit</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="Chapter_32.html"><a href="Chapter_32.html"><i class="fa fa-check"></i><b>32</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="32.1" data-path="Chapter_32.html"><a href="Chapter_32.html#visual-interpretation-of-regression"><i class="fa fa-check"></i><b>32.1</b> Visual interpretation of regression</a></li>
<li class="chapter" data-level="32.2" data-path="Chapter_32.html"><a href="Chapter_32.html#intercepts-slopes-and-residuals"><i class="fa fa-check"></i><b>32.2</b> Intercepts, slopes, and residuals</a></li>
<li class="chapter" data-level="32.3" data-path="Chapter_32.html"><a href="Chapter_32.html#regression-coefficients"><i class="fa fa-check"></i><b>32.3</b> Regression coefficients</a></li>
<li class="chapter" data-level="32.4" data-path="Chapter_32.html"><a href="Chapter_32.html#regression-line-calculation"><i class="fa fa-check"></i><b>32.4</b> Regression line calculation</a></li>
<li class="chapter" data-level="32.5" data-path="Chapter_32.html"><a href="Chapter_32.html#coefficient-of-determination"><i class="fa fa-check"></i><b>32.5</b> Coefficient of determination</a></li>
<li class="chapter" data-level="32.6" data-path="Chapter_32.html"><a href="Chapter_32.html#regression-assumptions"><i class="fa fa-check"></i><b>32.6</b> Regression assumptions</a></li>
<li class="chapter" data-level="32.7" data-path="Chapter_32.html"><a href="Chapter_32.html#regression-hypothesis-testing"><i class="fa fa-check"></i><b>32.7</b> Regression hypothesis testing</a>
<ul>
<li class="chapter" data-level="32.7.1" data-path="Chapter_32.html"><a href="Chapter_32.html#overall-model-significance"><i class="fa fa-check"></i><b>32.7.1</b> Overall model significance</a></li>
<li class="chapter" data-level="32.7.2" data-path="Chapter_32.html"><a href="Chapter_32.html#significance-of-the-intercept"><i class="fa fa-check"></i><b>32.7.2</b> Significance of the intercept</a></li>
<li class="chapter" data-level="32.7.3" data-path="Chapter_32.html"><a href="Chapter_32.html#significance-of-the-slope"><i class="fa fa-check"></i><b>32.7.3</b> Significance of the slope</a></li>
<li class="chapter" data-level="32.7.4" data-path="Chapter_32.html"><a href="Chapter_32.html#simple-regression-output"><i class="fa fa-check"></i><b>32.7.4</b> Simple regression output</a></li>
</ul></li>
<li class="chapter" data-level="32.8" data-path="Chapter_32.html"><a href="Chapter_32.html#prediction-with-linear-models"><i class="fa fa-check"></i><b>32.8</b> Prediction with linear models</a></li>
<li class="chapter" data-level="32.9" data-path="Chapter_32.html"><a href="Chapter_32.html#conclusion"><i class="fa fa-check"></i><b>32.9</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="Chapter_33.html"><a href="Chapter_33.html"><i class="fa fa-check"></i><b>33</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="33.1" data-path="Chapter_33.html"><a href="Chapter_33.html#adjusted-coefficient-of-determination"><i class="fa fa-check"></i><b>33.1</b> Adjusted coefficient of determination</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="Chapter_34.html"><a href="Chapter_34.html"><i class="fa fa-check"></i><b>34</b> <em>Practical</em>. Using regression</a>
<ul>
<li class="chapter" data-level="34.1" data-path="Chapter_34.html"><a href="Chapter_34.html#predicting-pyrogenic-carbon-from-soil-depth"><i class="fa fa-check"></i><b>34.1</b> Predicting pyrogenic carbon from soil depth</a></li>
<li class="chapter" data-level="34.2" data-path="Chapter_34.html"><a href="Chapter_34.html#predicting-pyrogenic-carbon-from-fire-frequency"><i class="fa fa-check"></i><b>34.2</b> Predicting pyrogenic carbon from fire frequency</a></li>
<li class="chapter" data-level="34.3" data-path="Chapter_34.html"><a href="Chapter_34.html#multiple-regression-depth-and-fire-frequency"><i class="fa fa-check"></i><b>34.3</b> Multiple regression depth and fire frequency</a></li>
<li class="chapter" data-level="34.4" data-path="Chapter_34.html"><a href="Chapter_34.html#large-multiple-regression"><i class="fa fa-check"></i><b>34.4</b> Large multiple regression</a></li>
<li class="chapter" data-level="34.5" data-path="Chapter_34.html"><a href="Chapter_34.html#predicting-temperature-from-fire-frequency"><i class="fa fa-check"></i><b>34.5</b> Predicting temperature from fire frequency</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="Chapter_35.html"><a href="Chapter_35.html"><i class="fa fa-check"></i><b>35</b> Randomisation</a>
<ul>
<li class="chapter" data-level="35.1" data-path="Chapter_35.html"><a href="Chapter_35.html#summary-of-parametric-hypothesis-testing"><i class="fa fa-check"></i><b>35.1</b> Summary of parametric hypothesis testing</a></li>
<li class="chapter" data-level="35.2" data-path="Chapter_35.html"><a href="Chapter_35.html#randomisation-approach"><i class="fa fa-check"></i><b>35.2</b> Randomisation approach</a></li>
<li class="chapter" data-level="35.3" data-path="Chapter_35.html"><a href="Chapter_35.html#randomisation-for-hypothesis-testing"><i class="fa fa-check"></i><b>35.3</b> Randomisation for hypothesis testing</a></li>
<li class="chapter" data-level="35.4" data-path="Chapter_35.html"><a href="Chapter_35.html#randomisation-assumptions"><i class="fa fa-check"></i><b>35.4</b> Randomisation assumptions</a></li>
<li class="chapter" data-level="35.5" data-path="Chapter_35.html"><a href="Chapter_35.html#bootstrapping"><i class="fa fa-check"></i><b>35.5</b> Bootstrapping</a></li>
<li class="chapter" data-level="35.6" data-path="Chapter_35.html"><a href="Chapter_35.html#randomisation-conclusions"><i class="fa fa-check"></i><b>35.6</b> Randomisation conclusions</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendexA.html"><a href="appendexA.html"><i class="fa fa-check"></i><b>A</b> Answers to chapter exercises</a>
<ul>
<li class="chapter" data-level="A.1" data-path="appendexA.html"><a href="appendexA.html#chapter-3"><i class="fa fa-check"></i><b>A.1</b> Chapter 3</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="appendexA.html"><a href="appendexA.html#exercise-3.1"><i class="fa fa-check"></i><b>A.1.1</b> Exercise 3.1:</a></li>
<li class="chapter" data-level="A.1.2" data-path="appendexA.html"><a href="appendexA.html#exercise-3.2"><i class="fa fa-check"></i><b>A.1.2</b> Exercise 3.2</a></li>
<li class="chapter" data-level="A.1.3" data-path="appendexA.html"><a href="appendexA.html#exercise-3.2-1"><i class="fa fa-check"></i><b>A.1.3</b> Exercise 3.2</a></li>
<li class="chapter" data-level="A.1.4" data-path="appendexA.html"><a href="appendexA.html#exercise-3.4"><i class="fa fa-check"></i><b>A.1.4</b> Exercise 3.4</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="appendexA.html"><a href="appendexA.html#chapter-8"><i class="fa fa-check"></i><b>A.2</b> Chapter 8</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="appendexA.html"><a href="appendexA.html#exercise-8.1"><i class="fa fa-check"></i><b>A.2.1</b> Exercise 8.1</a></li>
<li class="chapter" data-level="A.2.2" data-path="appendexA.html"><a href="appendexA.html#exercise-8.2"><i class="fa fa-check"></i><b>A.2.2</b> Exercise 8.2</a></li>
<li class="chapter" data-level="A.2.3" data-path="appendexA.html"><a href="appendexA.html#exercise-8.3"><i class="fa fa-check"></i><b>A.2.3</b> Exercise 8.3</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="appendexA.html"><a href="appendexA.html#chapter-14"><i class="fa fa-check"></i><b>A.3</b> Chapter 14</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="appendexA.html"><a href="appendexA.html#exercise-14.1"><i class="fa fa-check"></i><b>A.3.1</b> Exercise 14.1</a></li>
<li class="chapter" data-level="A.3.2" data-path="appendexA.html"><a href="appendexA.html#exercise-14.2"><i class="fa fa-check"></i><b>A.3.2</b> Exercise 14.2</a></li>
<li class="chapter" data-level="A.3.3" data-path="appendexA.html"><a href="appendexA.html#exercise-13.3"><i class="fa fa-check"></i><b>A.3.3</b> Exercise 13.3</a></li>
<li class="chapter" data-level="A.3.4" data-path="appendexA.html"><a href="appendexA.html#exercise-13.4"><i class="fa fa-check"></i><b>A.3.4</b> Exercise 13.4</a></li>
<li class="chapter" data-level="A.3.5" data-path="appendexA.html"><a href="appendexA.html#exercise-13.5"><i class="fa fa-check"></i><b>A.3.5</b> Exercise 13.5</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="appendexA.html"><a href="appendexA.html#chapter-17"><i class="fa fa-check"></i><b>A.4</b> Chapter 17</a>
<ul>
<li class="chapter" data-level="A.4.1" data-path="appendexA.html"><a href="appendexA.html#exercise-17.1"><i class="fa fa-check"></i><b>A.4.1</b> Exercise 17.1</a></li>
<li class="chapter" data-level="A.4.2" data-path="appendexA.html"><a href="appendexA.html#exercise-17.2"><i class="fa fa-check"></i><b>A.4.2</b> Exercise 17.2</a></li>
<li class="chapter" data-level="A.4.3" data-path="appendexA.html"><a href="appendexA.html#exercise-17.3"><i class="fa fa-check"></i><b>A.4.3</b> Exercise 17.3</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="appendexA.html"><a href="appendexA.html#chapter-20"><i class="fa fa-check"></i><b>A.5</b> Chapter 20</a>
<ul>
<li class="chapter" data-level="A.5.1" data-path="appendexA.html"><a href="appendexA.html#exercise-20.1"><i class="fa fa-check"></i><b>A.5.1</b> Exercise 20.1</a></li>
<li class="chapter" data-level="A.5.2" data-path="appendexA.html"><a href="appendexA.html#exercise-20.2"><i class="fa fa-check"></i><b>A.5.2</b> Exercise 20.2</a></li>
<li class="chapter" data-level="A.5.3" data-path="appendexA.html"><a href="appendexA.html#exercise-20.3"><i class="fa fa-check"></i><b>A.5.3</b> Exercise 20.3</a></li>
<li class="chapter" data-level="A.5.4" data-path="appendexA.html"><a href="appendexA.html#exercise-20.4"><i class="fa fa-check"></i><b>A.5.4</b> Exercise 20.4</a></li>
<li class="chapter" data-level="A.5.5" data-path="appendexA.html"><a href="appendexA.html#exercise-20.5"><i class="fa fa-check"></i><b>A.5.5</b> Exercise 20.5</a></li>
</ul></li>
<li class="chapter" data-level="A.6" data-path="appendexA.html"><a href="appendexA.html#chapter-23"><i class="fa fa-check"></i><b>A.6</b> Chapter 23</a>
<ul>
<li class="chapter" data-level="A.6.1" data-path="appendexA.html"><a href="appendexA.html#exercise-23.1"><i class="fa fa-check"></i><b>A.6.1</b> Exercise 23.1</a></li>
<li class="chapter" data-level="A.6.2" data-path="appendexA.html"><a href="appendexA.html#exercise-23.2"><i class="fa fa-check"></i><b>A.6.2</b> Exercise 23.2</a></li>
<li class="chapter" data-level="A.6.3" data-path="appendexA.html"><a href="appendexA.html#exercise-23.3"><i class="fa fa-check"></i><b>A.6.3</b> Exercise 23.3</a></li>
<li class="chapter" data-level="A.6.4" data-path="appendexA.html"><a href="appendexA.html#exercise-23.4"><i class="fa fa-check"></i><b>A.6.4</b> Exercise 23.4</a></li>
<li class="chapter" data-level="A.6.5" data-path="appendexA.html"><a href="appendexA.html#exercise-23.5"><i class="fa fa-check"></i><b>A.6.5</b> Exercise 23.5</a></li>
</ul></li>
<li class="chapter" data-level="A.7" data-path="appendexA.html"><a href="appendexA.html#chapter-28"><i class="fa fa-check"></i><b>A.7</b> Chapter 28</a>
<ul>
<li class="chapter" data-level="A.7.1" data-path="appendexA.html"><a href="appendexA.html#exercise-28.1"><i class="fa fa-check"></i><b>A.7.1</b> Exercise 28.1</a></li>
<li class="chapter" data-level="A.7.2" data-path="appendexA.html"><a href="appendexA.html#exercise-28.2"><i class="fa fa-check"></i><b>A.7.2</b> Exercise 28.2</a></li>
<li class="chapter" data-level="A.7.3" data-path="appendexA.html"><a href="appendexA.html#exercise-28.3"><i class="fa fa-check"></i><b>A.7.3</b> Exercise 28.3</a></li>
<li class="chapter" data-level="A.7.4" data-path="appendexA.html"><a href="appendexA.html#exercise-28.4"><i class="fa fa-check"></i><b>A.7.4</b> Exercise 28.4</a></li>
</ul></li>
<li class="chapter" data-level="A.8" data-path="appendexA.html"><a href="appendexA.html#chapter-31"><i class="fa fa-check"></i><b>A.8</b> Chapter 31</a>
<ul>
<li class="chapter" data-level="A.8.1" data-path="appendexA.html"><a href="appendexA.html#exercise-31.1"><i class="fa fa-check"></i><b>A.8.1</b> Exercise 31.1</a></li>
<li class="chapter" data-level="A.8.2" data-path="appendexA.html"><a href="appendexA.html#exercise-31.2"><i class="fa fa-check"></i><b>A.8.2</b> Exercise 31.2</a></li>
<li class="chapter" data-level="A.8.3" data-path="appendexA.html"><a href="appendexA.html#exercise-31.3"><i class="fa fa-check"></i><b>A.8.3</b> Exercise 31.3</a></li>
<li class="chapter" data-level="A.8.4" data-path="appendexA.html"><a href="appendexA.html#exercise-31.4"><i class="fa fa-check"></i><b>A.8.4</b> Exercise 31.4</a></li>
<li class="chapter" data-level="A.8.5" data-path="appendexA.html"><a href="appendexA.html#exercise-31.5"><i class="fa fa-check"></i><b>A.8.5</b> Exercise 31.5</a></li>
</ul></li>
<li class="chapter" data-level="A.9" data-path="appendexA.html"><a href="appendexA.html#chapter-34"><i class="fa fa-check"></i><b>A.9</b> Chapter 34</a>
<ul>
<li class="chapter" data-level="A.9.1" data-path="appendexA.html"><a href="appendexA.html#exercise-34.1"><i class="fa fa-check"></i><b>A.9.1</b> Exercise 34.1</a></li>
<li class="chapter" data-level="A.9.2" data-path="appendexA.html"><a href="appendexA.html#exercise-34.2"><i class="fa fa-check"></i><b>A.9.2</b> Exercise 34.2</a></li>
<li class="chapter" data-level="A.9.3" data-path="appendexA.html"><a href="appendexA.html#exercise-34.3"><i class="fa fa-check"></i><b>A.9.3</b> Exercise 34.3</a></li>
<li class="chapter" data-level="A.9.4" data-path="appendexA.html"><a href="appendexA.html#exercise-34.4"><i class="fa fa-check"></i><b>A.9.4</b> Exercise 34.4</a></li>
<li class="chapter" data-level="A.9.5" data-path="appendexA.html"><a href="appendexA.html#exercise-33.5"><i class="fa fa-check"></i><b>A.9.5</b> Exercise 33.5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="uncertainty_derivation.html"><a href="uncertainty_derivation.html"><i class="fa fa-check"></i><b>B</b> Uncertainty derivation</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamental statistical concepts and techniques in the biological and environmental sciences: With jamovi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="appendexA" class="section level1 hasAnchor" number="36">
<h1><span class="header-section-number">A</span> Answers to chapter exercises<a href="appendexA.html#appendexA" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Answers to exercises in chapters are provided below.
Many questions are open-ended and intended to be thought provoking, and the answers to these questions that are provided below are mostly intended to explain the motivation underlying the question.
Numerical answers are also provided.
Answers are written in bold.
All datasets that are made tidy in the process of doing exercises can be found at <a href="https://osf.io/dxwyv" class="uri">https://osf.io/dxwyv</a> in the ’ exercise_answer_datasets ’, and in the links below.</p>
<div id="chapter-3" class="section level2 hasAnchor" number="36.1">
<h2><span class="header-section-number">A.1</span> Chapter 3<a href="appendexA.html#chapter-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-3.1" class="section level3 hasAnchor" number="36.1.1">
<h3><span class="header-section-number">A.1.1</span> Exercise 3.1:<a href="appendexA.html#exercise-3.1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>Seeds are tallied incorrectly</strong></li>
<li>Tallies are not counted correctly in the lab notebook</li>
<li><strong>Counts are not correctly input into spreadsheet</strong></li>
</ol>
<p><strong>You can download the tidy dataset from this exercises here: <a href="https://bradduthie.github.io/stats/data/Ch3_Exercise_1.csv" class="uri">https://bradduthie.github.io/stats/data/Ch3_Exercise_1.csv</a></strong></p>
</div>
<div id="exercise-3.2" class="section level3 hasAnchor" number="36.1.2">
<h3><span class="header-section-number">A.1.2</span> Exercise 3.2<a href="appendexA.html#exercise-3.2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How many columns did you need to create the new dataset? <strong>2 columns</strong></p>
<p>Are there any missing data in this dataset? <strong>There are no missing data.</strong></p>
<p><strong>The tidy dataset should include two columns, one for Species and the other for egg loads. It should have 54 rows (plus the header). You can download the dataset here: <a href="https://bradduthie.github.io/stats/data/Ch3_Exercise_2.csv" class="uri">https://bradduthie.github.io/stats/data/Ch3_Exercise_2.csv</a></strong></p>
</div>
<div id="exercise-3.2-1" class="section level3 hasAnchor" number="36.1.3">
<h3><span class="header-section-number">A.1.3</span> Exercise 3.2<a href="appendexA.html#exercise-3.2-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>The tidy dataset should include three columns, one for Species, one for Fruit, and one for Count. It should be have rows (plus the header). You can download the dataset here: <a href="https://bradduthie.github.io/stats/data/Ch3_Exercise_3.csv" class="uri">https://bradduthie.github.io/stats/data/Ch3_Exercise_3.csv</a></strong></p>
</div>
<div id="exercise-3.4" class="section level3 hasAnchor" number="36.1.4">
<h3><span class="header-section-number">A.1.4</span> Exercise 3.4<a href="appendexA.html#exercise-3.4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>What columns should this new dataset include? <strong>Species, wasp number, Head length (mm), Head width (mm), Thorax length (mm), Thorax width (mm), Abdomen length (mm), Abdomen width (mm)</strong></p>
<p>How many rows are needed? <strong>26 rows of data (plus the column header)</strong></p>
<p><strong>You can download the dataset here: <a href="https://bradduthie.github.io/stats/data/Ch3_Exercise_4.csv" class="uri">https://bradduthie.github.io/stats/data/Ch3_Exercise_4.csv</a></strong></p>
<p>What formula will you type into your empty spreadsheet cell to calculate <span class="math inline">\(V_{thorax}\)</span>? <strong>=(4/3) * 3.14 * (E2/2) * ( ( F2/2)^2 )</strong></p>
<p>What are some reasons that we might want to be cautious about our calculated wasp volumes? <strong>There is error associated with the measurement of fig wasp dimensions (e.g., length, width). There is also error because we are assuming that the head is a sphere and the thorax and abdomen are ellipses.</strong></p>
</div>
</div>
<div id="chapter-8" class="section level2 hasAnchor" number="36.2">
<h2><span class="header-section-number">A.2</span> Chapter 8<a href="appendexA.html#chapter-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-8.1" class="section level3 hasAnchor" number="36.2.1">
<h3><span class="header-section-number">A.2.1</span> Exercise 8.1<a href="appendexA.html#exercise-8.1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Mean: <strong>6.52 g C / kg soil</strong></p>
<p>Minimum: <strong>0.600 g C / kg soil</strong></p>
<p>Maximum: <strong>16.2 g C / kg soil</strong></p>
<p>Topsoil Mean: <strong>9.75 g C / kg soil</strong></p>
<p>Topsoil Minimum: <strong>4.00 g C / kg soil</strong></p>
<p>Topsoil Maximum: <strong>16.2 g C / kg soil</strong></p>
<p>Subsoil Mean: <strong>2.43 g C / kg soil</strong></p>
<p>Subsoil Minimum: <strong>0.600 g C / kg soil</strong></p>
<p>Subsoil Maximum: <strong>4.60 g C / kg soil</strong></p>
<p>Based on these samples in the dataset, can we really say for certain that the population mean of topsoil is higher than the population mean of subsoil?</p>
<p><strong>The sample means themselves do not tell us whether the population mean of topsoil will be bigger or smaller than that of subsoil, just that the sample means are different. We can use the data to calculate a standard error associated with the mean, which will give an indication of the level of confidence that is appropriate.</strong></p>
<p>What would make you more (or less) confident that topsoil and subsoil population means are different?</p>
<p><strong>The larger the sample size, the more confidence we have that the sample mean is close to the population mean. Also, the narrower the spread of the data, the more confidence we should have that the sample mean is close to the population mean.</strong></p>
</div>
<div id="exercise-8.2" class="section level3 hasAnchor" number="36.2.2">
<h3><span class="header-section-number">A.2.2</span> Exercise 8.2<a href="appendexA.html#exercise-8.2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Grand Mean length: <strong>1.59 cm</strong></p>
<p>Grand Mean height: <strong>1.46 cm</strong></p>
<p>Grand Mean width: <strong>1.57 cm</strong></p>
<p>Missing width row: <strong>Row 62</strong></p>
<p>Missing height row: <strong>Row 22</strong></p>
<p>Grand Mean length (mm): <strong>15.9 mm</strong></p>
<p>Grand Mean height (mm): <strong>14.6 mm</strong></p>
<p>Grand Mean width (mm): <strong>15.7 mm</strong></p>
<p>Do the differences between means in cm and the means in mm make sense? <strong>Yes. Note that means in ‘mm’ are ten times the value of the means in ‘cm’, as expected.</strong></p>
</div>
<div id="exercise-8.3" class="section level3 hasAnchor" number="36.2.3">
<h3><span class="header-section-number">A.2.3</span> Exercise 8.3<a href="appendexA.html#exercise-8.3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this case, how might assuming that figs are perfectly spherical affect the accuracy of our estimated fig volume?</p>
<p><strong>As figs are not perfectly spherical, the estimation will be inaccurate. It could be systematically inaccurate, i.e., it would likely consistently over- or under-estimate the true volume of the figs, but could also be randomly inaccurate as each fig will differ in shape a little so the approximation to a sphere will be differently wrong for each fig. Note, that the measuring equipment used (which, in fact, was a ruler in this case) will also limit the precision of the estimates.</strong></p>
<p>Mean: <strong>2150 mm^3</strong></p>
<p>Minimum: <strong>697 mm^3</strong></p>
<p>Maximum: <strong>4847 mm^3</strong></p>
<p>Check the option for ‘Histogram’ and see the new histogram plotted in the window to the
right. Draw a rough sketch of the histogram in the area below. <strong>Your drawing should include a histogram with fig volume ranging from under 1000 to about 5000, with most values betwee 1000 and 2500.</strong></p>
</div>
</div>
<div id="chapter-14" class="section level2 hasAnchor" number="36.3">
<h2><span class="header-section-number">A.3</span> Chapter 14<a href="appendexA.html#chapter-14" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-14.1" class="section level3 hasAnchor" number="36.3.1">
<h3><span class="header-section-number">A.3.1</span> Exercise 14.1<a href="appendexA.html#exercise-14.1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>You can download the tidy dataset from this exercises here: <a href="https://bradduthie.github.io/stats/data/Nymphaea_alba_tidy.csv" class="uri">https://bradduthie.github.io/stats/data/Nymphaea_alba_tidy.csv</a></strong></p>
</div>
<div id="exercise-14.2" class="section level3 hasAnchor" number="36.3.2">
<h3><span class="header-section-number">A.3.2</span> Exercise 14.2<a href="appendexA.html#exercise-14.2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Just looking at the histogram, write down what you think the following summary statistics will be.</p>
<p><strong>While it will never be necessary (or recommended) to try to work out the mean, median, and standard deviation of a distribution directly from a histogram, the point of this is to help you connect the numerical summary statistics with the visualisation of the data in the histogram. You should be able to recognise that the mean and median are likely somewhere between 5 to 6 by recognising this as the centre of the distribution. Working out the standard deviation is a bit more challenging, but the average deviation from the centre looks to be about 2 (i.e., most points are probably about 2 mm from the mean). If your own answer was a bit different, this is not a cause for concern, but if you are able to interpret the histogram successfully, it probably should not be off by more than 3-4 mm.</strong></p>
<p>Based on the histogram, do you think that the mean and median are the same? Why or why
not?</p>
<p><strong>The mean and median appear to be quite similar. The distribution is mostly symmetrical, so the mean and median will likely be very close, although it might have a bit of a positive skew to it.</strong></p>
<p>Write a caption for the histogram below.</p>
<p><strong>Figure: Distribution of petiole diameter (mm) from white water lillies (<em>Nymphaea alba</em>) collected from 7 Scottish lochs.</strong></p>
<p>Highest: <strong>Lily loch</strong></p>
<p>Lowest: <strong>Linne</strong></p>
</div>
<div id="exercise-13.3" class="section level3 hasAnchor" number="36.3.3">
<h3><span class="header-section-number">A.3.3</span> Exercise 13.3<a href="appendexA.html#exercise-13.3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>N: <strong>140</strong></li>
<li>Std. deviation: <strong>1.83</strong></li>
<li>Variance: <strong>3.36</strong></li>
<li>Minimum: <strong>1.57</strong></li>
<li>Maximum: <strong>9.93</strong></li>
<li>Range: <strong>8.36</strong></li>
<li>IQR: <strong>2.90</strong></li>
<li>Mean: <strong>5.52</strong></li>
<li>Median: <strong>5.56</strong></li>
<li>Mode: <strong>3.2</strong></li>
<li>Std. error of mean: <strong>0.155</strong></li>
</ul>
<p>Which of the 7 sites in the data set has the highest mean petiole diameter, and what is its
mean?</p>
<p>Site: <strong>Beag</strong></p>
<p>Mean: <strong>5.94 mm</strong></p>
<p>Which of the 7 sites has the lowest variance in petiole diameter, and what is its variance?</p>
<p>Site: <strong>Fidhle</strong></p>
<p>Variance: <strong>2.51 mm^2</strong></p>
<p>Can you find the first and third quartiles for each site?</p>
<p>Beag: <strong>7.13 mm</strong></p>
<p>Buic: <strong>6.33 mm</strong></p>
<p>Choille-Bharr: <strong>6.83 mm</strong></p>
<p>Creig-Moire: <strong>7.24 mm</strong></p>
<p>Fidhle: <strong>6.53 mm</strong></p>
<p>Lily_Loch: <strong>7.24 mm</strong></p>
<p>Linne: <strong>6.52 mm</strong></p>
</div>
<div id="exercise-13.4" class="section level3 hasAnchor" number="36.3.4">
<h3><span class="header-section-number">A.3.4</span> Exercise 13.4<a href="appendexA.html#exercise-13.4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>N: <strong>140</strong></li>
<li>Std. deviation: <strong>1.8</strong></li>
<li>Variance: <strong>3.4</strong></li>
<li>Minimum: <strong>1.6</strong></li>
<li>Maximum: <strong>9.9</strong></li>
<li>Range: <strong>8.4</strong></li>
<li>IQR: <strong>2.9</strong></li>
<li>Mean: <strong>5.5</strong></li>
<li>Median: <strong>5.6</strong></li>
<li>Mode: <strong>3.2</strong></li>
<li>Std. error of mean: <strong>0.16</strong></li>
</ul>
<p>Were you able to get a similar value from the histogram as calculated in Jamovi from the data? What can you learn from the histogram that you cannot from the summary statistics, and what can you learn from the summary statistics that you cannot from the histogram?</p>
<p><strong>Values might or might not be similar (it is not important that you can guess a mean or median to any degree of accuracy just by looking at a histogram). Note, however, that with the histogram, we can see the full shape of the distribution, which is not really possible (or at least, not easy), with the summary statistics alone. The summary statistics, in contrast, can give us specific numbers of central tendency or spread (e.g., mean, median, variance).</strong></p>
</div>
<div id="exercise-13.5" class="section level3 hasAnchor" number="36.3.5">
<h3><span class="header-section-number">A.3.5</span> Exercise 13.5<a href="appendexA.html#exercise-13.5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall back from Chapter 12; what information do these error bars convey about the estimated mean petiole diameter?</p>
<p><strong>Standard errors tell us how far our sample mean is expected to deviate from the true mean. Specifically, the standard error of the mean is the standard deviation of the sample means around the true mean. It is a measure for evaluating the uncertainty of the mean.</strong></p>
<p>What can you say about the mean petiole diameters across the different sites? Do these sites appear to have very different mean petiole diameters?</p>
<p><strong>Different sites appear to have similar means. Given the uncertainty indicated by the standard error, it is unclear if different sites have different mean petiole diameters (note, an ANOVA, which is introduced in Chapter 24, does not reject the null hypothesis that the means are the same).</strong></p>
<p>There were 20 total petiole diameters sampled from each site. If we were to go back out to these 7 sites and sample another 20 petiole diameters, could we really expect to get the exact same site means? Assuming the site means would be at least a bit different for our new sample, is it possible that the sites with the highest or lowest petiole diameters might also be different in our new sample? If so, then what does this say about our ability to make conclusions about the differences in petiole diameter among sites?</p>
<p><strong>If we were to go out and sample another 20 petiole diameters from each site, then we would not expect to get the exact same site means. The site means would be a bit different. The distribution of these sample means (with each repeated resampling of 20 and mean calculation) would be normally distributed around the true mean with a standard deviation approximately equal to the standard error of any given sample (such as the one in the bar plots above). It is possible that the rank order of mean petiole diameters might change entirely. Given this uncertainty, we cannot really say for sure which site population mean is really the highest or lowest.</strong></p>
</div>
</div>
<div id="chapter-17" class="section level2 hasAnchor" number="36.4">
<h2><span class="header-section-number">A.4</span> Chapter 17<a href="appendexA.html#chapter-17" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-17.1" class="section level3 hasAnchor" number="36.4.1">
<h3><span class="header-section-number">A.4.1</span> Exercise 17.1<a href="appendexA.html#exercise-17.1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, fill in Table 17.1 with counts, percentage, and the estimated probability of a player selecting a small, medium, or large dam.</p>
<table>
<caption>Table 17.1: Statistics of Power Up! decisions for dam size with answers.</caption>
<thead>
<tr class="header">
<th>Dam size</th>
<th>Counts</th>
<th>Percentage</th>
<th>Estimated Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Small</td>
<td><strong>21</strong></td>
<td><strong>28.4</strong></td>
<td><strong>0.284</strong></td>
</tr>
<tr class="even">
<td>Medium</td>
<td><strong>13</strong></td>
<td><strong>17.6</strong></td>
<td><strong>0.176</strong></td>
</tr>
<tr class="odd">
<td>Large</td>
<td><strong>40</strong></td>
<td><strong>54.1</strong></td>
<td><strong>0.541</strong></td>
</tr>
</tbody>
</table>
<p>What is the probability that this player chooses a small or a large dam?</p>
<p><strong>To get this probability, calculate the probability that the player chooses a small dam plus the probability that the player chooses a large dam: P(small or large) = 0.284 + 0.541 = 0.825</strong></p>
<p>Now suppose that 3 new players arrive and decide to play the game. What is the probability that all 3 of these new players choose a large dam?</p>
<p><strong>To get this probability, calculate the probability of choosing a large dam raised to the power of 3: P(3 large) = 0.541 <span class="math inline">\(\times\)</span> 0.541 <span class="math inline">\(\times\)</span> 0.541 = 0.541^{3} = 0.158</strong></p>
<p>What is the probability that the first player chooses a small dam, the second player chooses a medium dam, and the third player chooses a large dam?</p>
<p><strong>To get this probability, calculate the probability of choosing small dam, times a medium dam, times a large dam: P(Player 1 = small, Player 2 = medium, Player 3 = large) = 0.541 <span class="math inline">\(\times\)</span> 0.176 <span class="math inline">\(\times\)</span> 0.284 = 0.027</strong></p>
<p>Imagine that you randomly choose one of the 74 players with equal probability (i.e., every player is equally likely to be chosen). What is the probability that you choose player 20?</p>
<p><strong>To get this probability, we just need to calculate one divided by 74: P(Player 20) = 1/74 = 0.01351</strong></p>
<p>What is the probability that you choose player 20, then choose a different player with a large dam? As a hint, remember that you are now sampling without replacement. The second choice cannot be player 20 again, so the probability of choosing a player with a large dam has changed from the estimated probability in Table 17.1.</p>
<p><strong>To get this probability, we need to first recognise that there is a 1/74 probability (0.01351) of choosing Player 20. Player 20 chose a large dam, so the number of remaining players in the dataset is now 73, and now only 39 of them chose large dams. Hence, the probability of choosing a large dam from the remaining players is 39/73 (0.53425). To calculate the probability of both events happening, we need to multiply: P(Player 20, Large) = 0.01351 <span class="math inline">\(\times\)</span> 0.53425 = 0.00722</strong></p>
<p>Now, recreate the table in Figure 17.3 and estimate the probability that an Android user will choose to build a large dam.</p>
<p><strong>To get this probability, divide the number of android players that choose a large dam (31) by the total number of android users (56): P(Large | Android) = 31/56 = 0.554</strong></p>
<p>Is P(Large|Android) much different from the probability that any player chooses a large dam, as calculated in Table 17.1? Do you think that the difference is significant?</p>
<p><strong>This is a small difference, but not that much. It is probably not significant.</strong></p>
</div>
<div id="exercise-17.2" class="section level3 hasAnchor" number="36.4.2">
<h3><span class="header-section-number">A.4.2</span> Exercise 17.2<a href="appendexA.html#exercise-17.2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Use jamovi to find the mean and the standard deviation of player score (note, we can just say that score is unitless, so no need to include units).</p>
<p><strong>Mean score: 95.9</strong></p>
<p><strong>Standard deviation score: 22.3</strong></p>
<p>What is the probability of a player getting a score between 80 and 120?</p>
<p><strong><span class="math inline">\(P(80 \leq X \leq 120)\)</span> = 0.6222</strong></p>
<p>What is the probability of a player getting a score greater than 130?</p>
<p><strong><span class="math inline">\(P(X \geq 130)\)</span> = 0.0631</strong></p>
<p>Now try the following probabilities for different scores.</p>
<p><strong><span class="math inline">\(P(X \geq 120)\)</span> = 0.1399</strong></p>
<p><strong><span class="math inline">\(P(X \leq 100)\)</span> = 0.5729</strong></p>
<p><strong><span class="math inline">\(P(100 \leq X \leq 120)\)</span> = 0.2872</strong></p>
<p>What is the probability of a player getting a score lower than 70 or higher than 130?</p>
<p><strong><span class="math inline">\(P(X \leq 70 \: \cup \: X \geq 130)\)</span> = 1 - 0.8142 = 0.1858</strong></p>
<p>There is more than one way to figure this last one out. How did you do it, and what was your reasoning?</p>
<p><strong>We can find the total area under the curve between 70 and 130 using jamovi. Since the entire area under the curve must sum to 1, if we subtract this area (0.8142) from 1, then we are left with the area in the tails of the distribution (i.e., lower than 70 or higher than 130).</strong></p>
</div>
<div id="exercise-17.3" class="section level3 hasAnchor" number="36.4.3">
<h3><span class="header-section-number">A.4.3</span> Exercise 17.3<a href="appendexA.html#exercise-17.3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How would you describe the shape of the distribution of v1?</p>
<p><strong>The distribution of v1 is approximately uniform.</strong></p>
<p>Sketch what you predict the shape of its distribution will be below.</p>
<p><strong>The ‘all_means’ values should have the shape of a normal distribution (roughly) as it is the distribution of the sample means. The CLT states that the original distribution (in this case uniform) does not matter; when a set of sample means are individually calculated the dataset will form a normal distribution.</strong></p>
<p>As best you can, explain why the shapes of the two distributions differ.</p>
<p><strong>A consequence of the central limit theorem is that the distribution of sample means should be normal regardless of the distribution of the sample data. In this case, the sample data were uniformly distributed, but the means of the 40 datasets is normally distributed.</strong></p>
<p>Now try increasing the number of trials to 200. What happens to the histogram? What about when you increase the number of trials to 2000?</p>
<p><strong>The distribution of sample means appears to get closer to a normal distribution.</strong></p>
<p>Try playing around with different source distributions, sample sizes, and numbers of trials. What general conclusion can you make about the distribution of sample means from the different distributions?</p>
<p><strong>Using clt-Demonstrations: Increasing number of trials shows dataset looking more and more normally distributed. General conclusion should be that the distribution of sample means is approximately normal, regardless of the original distribution.</strong></p>
</div>
</div>
<div id="chapter-20" class="section level2 hasAnchor" number="36.5">
<h2><span class="header-section-number">A.5</span> Chapter 20<a href="appendexA.html#chapter-20" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-20.1" class="section level3 hasAnchor" number="36.5.1">
<h3><span class="header-section-number">A.5.1</span> Exercise 20.1<a href="appendexA.html#exercise-20.1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Do these data appear to be roughly normal? Why or why not?</p>
<p><strong>The data appear to be normal. The distribution is mostly symmetric with no clear outliers.</strong></p>
<p>Next, calculate the grand mean and standard deviation of tree DBH (i.e., the mean and standard deviation of trees across all sites).</p>
<p>Grand Mean: <strong>36.93</strong></p>
<p>Grand Standard Deviation: <strong>10.96</strong></p>
<p>Using the same principles, what is the cumulative 0.4 quantile for the DBH data? <strong>34.15 cm</strong></p>
<p>From the Results table on the right, what interval of DBH values will contain 95% of the probability density around the mean? <strong>15.45-58.41 cm</strong></p>
<p>From the Descriptives panel in Jamovi (recall that this is under the ‘Exploration’
button), find the standard error of DBH. Std. error of Mean: <strong>1.000</strong></p>
<p>Based on the Results table, what can you infer are the lower and upper 95%
confidence intervals (CIs) around the mean?</p>
<p>Lower 95% CI: <strong>34.97</strong></p>
<p>Upper 95% CI: <strong>38.89</strong></p>
<p>From this Descriptives table now, write the lower and upper 95% CIs below.</p>
<p>Lower 95% CI: <strong>34.95</strong></p>
<p>Upper 95% CI: <strong>38.91</strong></p>
</div>
<div id="exercise-20.2" class="section level3 hasAnchor" number="36.5.2">
<h3><span class="header-section-number">A.5.2</span> Exercise 20.2<a href="appendexA.html#exercise-20.2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From these quantiles, what is the proper z-score to use in the equations for LCI
and UCI above?</p>
<p>z-score: <strong>1.96</strong></p>
<p>Now, use the values of <span class="math inline">\(\bar{x}\)</span>, z, and SE for DBH in the equations above to calculate lower and upper 95% confidence intervals again.</p>
<p>Lower 95% CI: <strong>34.97</strong></p>
<p>Upper 95% CI: <strong>38.89</strong></p>
<p>Are these confidence intervals the same as what you calculated in Exercise 19.1?</p>
<p><strong>These confidence intervals are the same as those calculated from the normal distribution, bu they are slightly different from those from the ‘Descriptives’ menu as those ones are calculated with t-scores (which are more accurate), rather than z-scores.</strong></p>
<p>What are the appropriate df for DBH? <strong>df: 120 - 1 = 119</strong></p>
<p>From the Results table, what is the proper t-score to use in the equations for LCI and UCI? <strong>t-score: 1.980</strong></p>
<p>Again, use the values of <span class="math inline">\(\bar{x}\)</span>, t, and SE for DBH in the equations above to calculate lower and upper 95% confidence intervals.</p>
<p>Lower 95% CI: <strong>34.95</strong></p>
<p>Upper 95% CI: <strong>38.91</strong></p>
<p>Reflect on any similarities or differences that you see in all of these different ways of calculating confidence intervals.</p>
<p><strong>The confidence intervals are very similar, but not exactly the same as those calculated with z-scores. This is because the sample size is 120 and degrees of freedom is therefore 120 - 1 = 119, which is quite large and as the sample size becomes larger the t-scores and z-scores become more similar. While there is no fixed threshold, usually when the sample size is more than about 30, the difference between the two methods is sufficiently small as to not make an important difference.</strong></p>
</div>
<div id="exercise-20.3" class="section level3 hasAnchor" number="36.5.3">
<h3><span class="header-section-number">A.5.3</span> Exercise 20.3<a href="appendexA.html#exercise-20.3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From the Descriptives tool in jamovi, write the sample sizes for DBH split by site below.</p>
<p>Site 1182: N = <strong>4</strong></p>
<p>Site 1223: N = <strong>22</strong></p>
<p>Site 3008: N = <strong>10</strong></p>
<p>Site 10922: N = <strong>84</strong></p>
<p>For which of these sites would you predict CIs calculated from z-scores versus t- scores to differ the most? <strong>Site: 1182 (note that this site has the lowest sample size)</strong></p>
<p>Now, fill in the table below reporting 95% CIs calculated using each distribution from the 4 sites using any method you prefer.</p>
<table>
<caption>Table 20.1: 95 per cent Confidence intervals calculated for tree diameter at breast height (DBH) in cm.</caption>
<thead>
<tr class="header">
<th>Site</th>
<th>N</th>
<th>95% CIs (Normal)</th>
<th>95% CIs (t-distribution)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1182</td>
<td><strong>4</strong></td>
<td><strong>42.73-57.57</strong></td>
<td><strong>38.09-62.21</strong></td>
</tr>
<tr class="even">
<td>1223</td>
<td><strong>22</strong></td>
<td><strong>21.56-24.16</strong></td>
<td><strong>21.48-24.24</strong></td>
</tr>
<tr class="odd">
<td>3008</td>
<td><strong>10</strong></td>
<td><strong>51.49-61.13</strong></td>
<td><strong>50.75-61.87</strong></td>
</tr>
<tr class="even">
<td>10922</td>
<td><strong>84</strong></td>
<td><strong>36.03-39.25</strong></td>
<td><strong>36.07-39.27</strong></td>
</tr>
</tbody>
</table>
<p>Next, do the same, but now calculate 99% CIs instead of 95% CIs.</p>
<table>
<caption>Table 20.2: 99 per cent Confidence intervals calculated for tree diameter at breast height (DBH) in cm.</caption>
<thead>
<tr class="header">
<th>Site</th>
<th>N</th>
<th>99% CIs (Normal)</th>
<th>99% CIs (t-distribution)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1182</td>
<td><strong>4</strong></td>
<td><strong>40.39-59.91</strong></td>
<td><strong>28.02-72.28</strong></td>
</tr>
<tr class="even">
<td>1223</td>
<td><strong>22</strong></td>
<td><strong>21.15-24.57</strong></td>
<td><strong>20.98-24.74</strong></td>
</tr>
<tr class="odd">
<td>3008</td>
<td><strong>10</strong></td>
<td><strong>49.97-62.65</strong></td>
<td><strong>48.32-64.30</strong></td>
</tr>
<tr class="even">
<td>10922</td>
<td><strong>84</strong></td>
<td><strong>35.60-39.74</strong></td>
<td><strong>35.55-39.79</strong></td>
</tr>
</tbody>
</table>
<p>What do you notice about the difference between CIs calculated from the normal distribution versus the t-distribution across the different sites?</p>
<p><strong>The t-distribution gives a slightly wider spread than the normal distribution, and the difference increases as sample size gets smaller.</strong></p>
<p>In your own words, based on this practical and what you have read from the lab workbook and any other material, what do these confidence intervals actually mean?</p>
<p><strong>Confidence intervals: if you take a sample and calculate the 95% (or 99%) confidence interval, and then go to the same population and resample that population numerous times then there is a 95% chance the new sample mean will be within the confidence intervals calculated at the 95% level (and 99% chance that it would be within the confidence intervals calculated at the 99% level).</strong></p>
</div>
<div id="exercise-20.4" class="section level3 hasAnchor" number="36.5.4">
<h3><span class="header-section-number">A.5.4</span> Exercise 20.4<a href="appendexA.html#exercise-20.4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From the Descriptives options, find the number of sites grazed versus not grazed.</p>
<p>Grazed: <strong>4</strong></p>
<p>Not Grazed: <strong>20</strong></p>
<p>From these counts above, what is the estimate (<span class="math inline">\(p\)</span>, or more technically <span class="math inline">\(\hat{p}\)</span>, with the hat indicating that it is an estimate) of the proportion of sites that are grazed?</p>
<p>p: <strong>4 / (20 + 4) = 0.166667</strong></p>
<p>We can estimate <span class="math inline">\(p\)</span> using <span class="math inline">\(p\)</span>, and <span class="math inline">\(N\)</span> is the total sample size. Using the above equation, what is the standard error of <span class="math inline">\(p\)</span>?</p>
<p><span class="math display">\[SE(p) = \sqrt{\frac{0.166667(1 - 0.166667)}{24}} = 0.0761\]</span></p>
<p>Using this standard error, what are the Wald lower and upper 95% confidence intervals around <span class="math inline">\(p\)</span>?</p>
<p>Wald <span class="math inline">\(LCI_{95\%} = 0.166667 - (1.96 \times 0.0761) =\)</span> <strong>0.0175</strong></p>
<p>Wald <span class="math inline">\(UCI_{95\%} = 0.166667 + (1.96 \times 0.0761) =\)</span> <strong>0.3158</strong></p>
<p>Next, find the lower and upper 99% CIs around <span class="math inline">\(p\)</span> and report them below.</p>
<p>Wald <span class="math inline">\(LCI_{99\%} = 0.166667 - (2.58 \times 0.0761) =\)</span> <strong>-0.0297</strong></p>
<p>Wald <span class="math inline">\(UCI_{99\%} = 0.166667 + (2.58 \times 0.0761) =\)</span> <strong>0.3630</strong></p>
<p>Do you notice anything unusual about the lower 99% CI? <strong>The lower 99% CI is a negative number, which is not possible for a proportion.</strong></p>
<p><span class="math inline">\(p\)</span>: <strong>0.16667</strong></p>
<p>Clopper-Pearson <span class="math inline">\(LCI_{95\%} =\)</span> <strong>0.04735</strong></p>
<p>Clopper-Pearson <span class="math inline">\(UCI_{95\%} =\)</span> <strong>0.37384</strong></p>
<p>To calculate 99% CIs, change the number in the Interval box from 95 to 99.
Report the 99% CIs below.</p>
<p>Clopper-Pearson <span class="math inline">\(LCI_{99\%} =\)</span> <strong>0.02947</strong></p>
<p>Clopper-Pearson <span class="math inline">\(UCI_{99\%} =\)</span> <strong>0.43795</strong></p>
<p>What do you notice about the difference between the Wald CIs and the Clopper-Pearson CIs?</p>
<p><strong>The Clopper-Pearson CIs are a bit wider than the Wald CIs, thereby suggesting that a wider range of values is needed to encompass the means for a given level of confidence. The Clopper-Pearson CIs have higher upper confidence intervals, but also higher lower confidence intervals (and the 99% Clopper-Pearson CI does not overlap zero).</strong></p>
</div>
<div id="exercise-20.5" class="section level3 hasAnchor" number="36.5.5">
<h3><span class="header-section-number">A.5.5</span> Exercise 20.5<a href="appendexA.html#exercise-20.5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>First consider an 80% CI.</p>
<p><span class="math inline">\(LCI_{80\%} =\)</span> <strong>0.47359</strong></p>
<p><span class="math inline">\(UCI_{80\%} =\)</span> <strong>0.75942</strong></p>
<p>Next, calculate 95% CIs for the proportion of sites classified as Ancient woodland.</p>
<p><span class="math inline">\(LCI_{95\%} =\)</span> <strong>0.40594</strong></p>
<p><span class="math inline">\(UCI_{95\%} =\)</span> <strong>0.81201</strong></p>
<p>Finally, calculate 99% CIs for the proportion of sites classified as Ancient woodland.</p>
<p><span class="math inline">\(LCI_{99\%} =\)</span> <strong>0.34698</strong></p>
<p><span class="math inline">\(UCI_{99\%} =\)</span> <strong>0.85353</strong></p>
</div>
</div>
<div id="chapter-23" class="section level2 hasAnchor" number="36.6">
<h2><span class="header-section-number">A.6</span> Chapter 23<a href="appendexA.html#chapter-23" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-23.1" class="section level3 hasAnchor" number="36.6.1">
<h3><span class="header-section-number">A.6.1</span> Exercise 23.1<a href="appendexA.html#exercise-23.1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Report these below.</p>
<p>N: <strong>21</strong></p>
<p><span class="math inline">\(\bar{x}\)</span>: <strong>58.76</strong></p>
<p><span class="math inline">\(s\)</span>: <strong>8.687</strong></p>
<p>What kind(s) of statistical test would be most appropriate to use in this case, and what is the null hypothesis (<span class="math inline">\(H_{0}\)</span>) of the test?</p>
<p>Test to use: <strong>One sample t-test</strong></p>
<p><span class="math inline">\(H_{0}\)</span>: <strong>The overall student scores were sampled from a population with a mean of 60.1</strong></p>
<p>What is the alternative hypothesis (<span class="math inline">\(H_{A}\)</span>), and should you use a one or two-tailed test?</p>
<p><span class="math inline">\(H_{A}\)</span>: <strong>The overall student scores were sampled from a population with a mean lower than 60.1</strong></p>
<p>One or two tailed? <strong>One-tailed</strong></p>
<p>From the Normality Test table, what is the p-value of the Shapiro-Wilk test? <strong>P = 0.112</strong></p>
<p>Based on this p-value, should we reject the null hypothesis?:</p>
<p><strong>No, we do not reject the null hypothesis that the data are normally distributed.</strong></p>
<p>On the right panel of jamovi, you will see a table with the t-statistic, degrees of freedom, and p-value of the one sample t-test. Write these values down below.</p>
<p>t-statistic: <strong>-0.7067</strong></p>
<p>degrees of freedom: <strong>20</strong></p>
<p>p-value: <strong>0.224</strong></p>
<p>Based on the p-value, should you reject the null hypothesis that your students’ mean overall grade is the same as the national average? Why or why not?</p>
<p><strong>We should not reject the null hypothesis because our p-value is greater than our threshold Type I error rate of 0.05 (i.e., P &gt; 0.05). Assuming that the null hypothesis is true, the probability getting a t-statistic as extreme as the one we observed is only about 1 in 4, which is not especially unlikely.</strong></p>
<p>Based on this test, how would you respond to your colleague who is concerned that your students are performing below the national average?</p>
<p><strong>There is no evidence that students in this class are performing below the national average.</strong></p>
<p>Is there an assumption that might be particularly suspect when comparing the scores of students in a single classroom with a national average? Why or why not?</p>
<p><strong>The students in this classroom are unlikely to be a random sample from the overall population. There may be other factors affecting student test scores that have nothing to do with the quality of the instruction.</strong></p>
</div>
<div id="exercise-23.2" class="section level3 hasAnchor" number="36.6.2">
<h3><span class="header-section-number">A.6.2</span> Exercise 23.2<a href="appendexA.html#exercise-23.2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Is there any reason to believe that the data are not normally distributed?</p>
<p><strong>No, the Shapiro-Wilk test gives us no reason to reject the null hypothesis that the data are normally distributed (P &gt; 0.05).</strong></p>
<p>We want to know if student grades have improved. What is the null hypothesis (<span class="math inline">\(H_{0}\)</span>) and alternative hypothesis (<span class="math inline">\(H_{A}\)</span>) in this case?</p>
<p><span class="math inline">\(H_{0}\)</span>: <strong>The mean change in student grade is 0.</strong></p>
<p><span class="math inline">\(H_{A}\)</span>: <strong>The mean change in student grade is greater than 0</strong></p>
<p>Write these values down below.</p>
<p>t-statistic: <strong>-8.18</strong></p>
<p>degrees of freedom: <strong>20</strong></p>
<p>p-value: <strong>P &lt; 0.001</strong></p>
<p>Based on this p-value, should you reject or fail to reject your null hypothesis? What can you then conclude about student test scores?</p>
<p><strong>Because P &lt; 0.05, we reject the null hypothesis. We can conclude that the mean score for Test 1 is less than the mean score for Test 2, so the grades appear to have improved.</strong></p>
</div>
<div id="exercise-23.3" class="section level3 hasAnchor" number="36.6.3">
<h3><span class="header-section-number">A.6.3</span> Exercise 23.3<a href="appendexA.html#exercise-23.3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We are not interested in whether the scores are higher or lower than 62, just that
they are different. Consequently, what should our alternative hypothesis (<span class="math inline">\(H_{A}\)</span>) be?</p>
<p><span class="math inline">\(H_{A}\)</span>: <strong>Test 3 scores were sampled from a population with a mean not equal to 62.</strong></p>
<p>What is the p-value of the Shaprio-Wilk test this time? <strong>P = 0.022</strong></p>
<p>What inference can you make from the Q-Q plot? Do the points fall along the diagonal line?</p>
<p><strong>The points appear to be a bit curved. They do not cleanly fall along the diagonal line.</strong></p>
<p>Based on the Shapiro-Wilk test and Q-Q plot, is it safe to assume that the Test 3 scores are normally distributed?</p>
<p><strong>Based on the Shapiro-Wilk test and the Q-Q plot, we should not assume that the data are normally distributed.</strong></p>
<p>What are the null and alternative hypotheses of this test?</p>
<p><span class="math inline">\(H_{0}\)</span>: <strong>Test 3 scores were sampled from a population with a median of 62.</strong></p>
<p><span class="math inline">\(H_{A}\)</span>: <strong>Test 3 scores were sampled from a population with a median not equal to 62.</strong></p>
<p>What is the test statistic (not the p-value) for the Wilcoxon test? Test statistic: <strong>53</strong></p>
<p>Based on what you learned in Chapter 22.5.1, what does this test statistic actually mean?</p>
<p><strong>It means that if we subtract 62 from the Test 3 values, then rank each by its absolute value, the sum of ranks that came from positive values should equal 53.</strong></p>
<p>Now look at the p-value for the Wilcoxon test. What is the p-value, and what
should you conclude from it? <strong>P: 0.055</strong></p>
<p>Conclusion: <strong>We do not reject the null hypothesis that the median Test 3 score is 62.</strong></p>
</div>
<div id="exercise-23.4" class="section level3 hasAnchor" number="36.6.4">
<h3><span class="header-section-number">A.6.4</span> Exercise 23.4<a href="appendexA.html#exercise-23.4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One or two tailed? <strong>Two-tailed</strong></p>
<p>Based on the Assumption Checks in jamovi (and Figure 23.5), what can you conclude about the t-test assumptions?</p>
<p><strong>The data appear to be normally distributed, but the groups do not have equal variances.</strong></p>
<p>What is the p-value for the Levene’s test? P: <strong>0.021</strong></p>
<p>Based on what you learnt in Chapter 22.2, what is the appropriate test to run in this case? Test: <strong>Welch’s independent samples t-test</strong></p>
<p>Check the box for the correct test, then report the test statistic and p-value from the table that appears in the right panel.</p>
<p>Test statistic: <strong>-0.3279</strong></p>
<p>P = <strong>0.745</strong></p>
<p>What can you conclude from this t-test?</p>
<p><strong>There is no evidence to reject the null hypothesis that both years were sampled from a population from the same mean score. The overall scores appear to be the same between years.</strong></p>
</div>
<div id="exercise-23.5" class="section level3 hasAnchor" number="36.6.5">
<h3><span class="header-section-number">A.6.5</span> Exercise 23.5<a href="appendexA.html#exercise-23.5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Below, summarise the hypotheses for this new test.</p>
<p><span class="math inline">\(H_{0}\)</span>: <strong>Test 3 scores in 2022 and 2023 were sampled from a population with the same mean.</strong></p>
<p><span class="math inline">\(H_{A}\)</span>: <strong>Test 3 scores in 2022 and 2023 were sampled from a population with different means.</strong></p>
<p>Is this a one or two tailed test?: <strong>Two-tailed test</strong></p>
<p>Do the variances appear to be the same for Test 3 scores in 2022 versus 2023? How can you make this conclusion?</p>
<p><strong>The homogeneity of variances test (i.e., Levene’s test) show a test statistic of F = 0.1379 and a p-value of P = 0.712, so there is no evidence to reject the null hypothesis that the two years have different variances.</strong></p>
<p>What is the p-value of the Shapiro-Wilk test? <strong>P &lt; 0.001</strong></p>
<p>Now, have a look at the Q-Q plot. What can you infer from this plot about the normality of the data, and why?</p>
<p><strong>The data appear to deviate from the diagonal line, suggesting non-normality.</strong></p>
<p>Based on what you found from testing the model assumptions above, and the material in Chapter 22, what test is the most appropriate one to use?</p>
<p>Test: <strong>Mann-Whitney U test</strong></p>
<p>Run the above test in jamovi, then report the test statistic and p-value below.</p>
<p>Test statistic: <strong>221.0</strong></p>
<p>p-value: <strong>0.487</strong></p>
<p>Based on what you learned in Chapter 22.5.2, what does this test statistic actually mean?</p>
<p><strong>If we rank the full dataset (all Test 3 scores regardless of year), then sum up the ranks of 2022, the rank sum would be 221.</strong></p>
<p>Finally, what conclusions can you make about Test 3 scores in 2022 versus 2023?</p>
<p><strong>There appears to be no difference in Test 3 scores between 2022 and 2023. We do not reject the null hypothesis that the medians (technically, the distributions) differ between years.</strong></p>
<p>What could you do to test the null hypothesis that the change in scores from Test 1 to Test 2 is the same between years?</p>
<p><strong>Because the paired samples t-test is really just a one-sample t-test, we could first calculate the change from Test 1 to Test 2. That is, create a new column of data that is Change = Test 1 - Test 2. We could then use an independent samples t-test to check if the change differs between 2022 and 2023.</strong></p>
</div>
</div>
<div id="chapter-28" class="section level2 hasAnchor" number="36.7">
<h2><span class="header-section-number">A.7</span> Chapter 28<a href="appendexA.html#chapter-28" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-28.1" class="section level3 hasAnchor" number="36.7.1">
<h3><span class="header-section-number">A.7.1</span> Exercise 28.1<a href="appendexA.html#exercise-28.1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>What are the null (<span class="math inline">\(H_{0}\)</span>) and alternative (<span class="math inline">\(H_{A}\)</span>) hypotheses for the t-test?</p>
<p><span class="math inline">\(H_{O}\)</span>: <strong>Mean nitrogen concentration is the same in both sites</strong></p>
<p><span class="math inline">\(H_{A}\)</span>: <strong>Mean nitrogen concentration is not the same in both sites</strong></p>
<p>What can you conclude from these 2 tests?</p>
<p>Normality conclusion: <strong>Do not reject null hypothesis that data are normally distributed</strong></p>
<p>Homogeneity of variances conclusion: <strong>Do not reject null hypothesis that groups have the same variances</strong></p>
<p>Given the conclusions from the checks of normality and homogeneity of variances above, what kind of test should you use to see if the mean Nitrogen concentration is significantly different in Funda versus Bailundo? Test: <strong>Independent samples Student’s t-test</strong></p>
<p>Run the test above in jamovi. What is the p-value of the test, and what conclusion do you make about Nitrogen concentration at the two sites? <strong>P = 0.030</strong></p>
<p>Conclusion: <strong>Mean nitrogen concentration is different in the 2 sites (reject null hypothesis)</strong></p>
<p>Write down the test statistic (F), degrees of freedom, and p-values from this table below.</p>
<p>F: <strong>4.98377</strong></p>
<p>df1: <strong>1</strong></p>
<p>df2: <strong>49</strong></p>
<p>P: <strong>0.030</strong></p>
<p>What is the approximate area under the curve (i.e., the orange area) where the F value on the x-axis is greater than your calculated F? P: <strong>About 0.03 for F = 5</strong></p>
<p>Approximately, what is this threshold F value above which we will reject the null hypothesis?
Approximate threshold F: <strong>Somewhere between 4 and 4.1</strong></p>
<p>What should you conclude regarding the null hypothesis that sites have the same mean?
Conclusion: <strong>Reject the null hypothesis that sites have the same mean</strong></p>
<p>Look again at the p-value from the one-way ANOVA output and the Student’s t-test output. Are the two values the same, or different? Why might this be?</p>
<p><strong>The 2 p-values are the exact same. The independent Student’s t-test and the one-way ANOVA are actually testing the same null hypothesis and making the same assumptions. One test is just using the t-distribution (t-test) to find the probability of rejecting the null hypothesis if it is true (i.e., the p-value). The other test (ANOVA) is using the F-distribution to find the same p-value.</strong></p>
</div>
<div id="exercise-28.2" class="section level3 hasAnchor" number="36.7.2">
<h3><span class="header-section-number">A.7.2</span> Exercise 28.2<a href="appendexA.html#exercise-28.2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>What can you conclude?</p>
<p>Normality conclusion: <strong>Do not reject the null hypothesis of normality</strong></p>
<p>Homogeneity of variance conclusion: <strong>Do not reject the null hypothesis that the Profiles have the same variances.</strong></p>
<p>What are the output statistics in the One-Way ANOVA table?</p>
<p>F: <strong>3.43221</strong></p>
<p>df1: <strong>2</strong></p>
<p>df2: <strong>48</strong></p>
<p>P: <strong>0.040</strong></p>
<p>From these statistics, what do you conclude about the difference in Nitrogen concentration among profiles?</p>
<p>Conclusion: <strong>Profiles do not have the same mean nitrogen concentration (reject null hypothesis)</strong></p>
<p>Write down the ‘Probability’ value from the Results table in the panel to the right.
Probability: <strong>0.04052</strong></p>
<p>From the Results table, what is the critical F value (‘Quantile’), above which we would reject the null hypothesis that all groups have the same mean? Critical <strong>F value: 3.19</strong></p>
<p>Fill in the table below (Table 28.1) with the information for degrees of freedom, F, and P.</p>
<table>
<caption>Table 28.1: ANOVA output testing the null hypothesis that mean Nitrogen concentration is the same across 3 different soil profiles in Angola.</caption>
<colgroup>
<col width="14%" />
<col width="23%" />
<col width="10%" />
<col width="20%" />
<col width="16%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Sum of Squares</th>
<th>df</th>
<th>Mean Square</th>
<th>F</th>
<th>p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Profile</td>
<td><strong>16888.18606</strong></td>
<td><strong>2</strong></td>
<td><strong>8444.09303</strong></td>
<td><strong>3.43221</strong></td>
<td><strong>0.040</strong></td>
</tr>
<tr class="even">
<td>Residuals</td>
<td><strong>118092.02927</strong></td>
<td><strong>48</strong></td>
<td><strong>2460.25061</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div id="exercise-28.3" class="section level3 hasAnchor" number="36.7.3">
<h3><span class="header-section-number">A.7.3</span> Exercise 28.3<a href="appendexA.html#exercise-28.3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Find the p-values associated with the Tukey’s HSD (<span class="math inline">\(P_{Tukey}\)</span>) for each profile pairing. Report these below.</p>
<p>Tukey’s HSD Lower - Middle: <strong>P = 0.705</strong>
Tukey’s HSD Lower - Upper: <strong>P = 0.193</strong>
Tukey’s HSD Middle - Upper: <strong>P = 0.035</strong></p>
<p>From this output, what can we conclude about the difference among soil profiles?</p>
<p><strong>Middle and upper profiles appear to have significantly different mean nitrogen concentrations, but other combinations are not significant.</strong></p>
<p>Report the p-values for the Bonferonni correction below.</p>
<p>Bonferonni Lower - Middle: <strong>P = 1.000</strong>
Bonferonni Lower - Upper: <strong>P = 0.253</strong>
Bonferonni Middle - Upper: <strong>P = 0.040</strong></p>
<p>In general, how are the p-values different between the Tukey’s HSD and the Boneferroni correction? Are they about the same, higher, or lower?</p>
<p><strong>In general, p-values from the Bonferonni correction are higher.</strong></p>
<p>In general, how are the p-values different between the Tukey’s HSD and the Boneferroni correction? Are they about the same, higher, or lower?</p>
<p><strong>In general, we have a lower probability of making a Type I error with the Bonferonni test.</strong></p>
</div>
<div id="exercise-28.4" class="section level3 hasAnchor" number="36.7.4">
<h3><span class="header-section-number">A.7.4</span> Exercise 28.4<a href="appendexA.html#exercise-28.4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How would you describe the distribution? Do the data appear to be normally distributed?</p>
<p><strong>The histogram appears to show a distribution that is very right skewed. This does not look normally distriubted.</strong></p>
<p>From the Levene’s test, the Shapiro-Wilk test, and the Q-Q plot, what assumptions of ANOVA might be violated?</p>
<p><strong>From the Shapiro-Wilk test (P &lt; 0.001) and the Levene’s test (P = 0.024), it appears that the assumptions of normality and equal variances are violated.</strong></p>
<p>Report these values below.</p>
<p>Chi-square: <strong>0.38250</strong></p>
<p>df: <strong>2</strong></p>
<p>P: <strong>0.826</strong></p>
<p>From the above output, should we reject or not reject our null hypothesis? <span class="math inline">\(H_{0}\)</span>: <strong>Do not reject null hypothesis</strong></p>
<p>Write these null hypotheses down below (the order does not matter).</p>
<p>First <span class="math inline">\(H_{0}\)</span>: <strong>Mean Nitrogen concentration does not differ among sites</strong></p>
<p>Second <span class="math inline">\(H_{0}\)</span>: <strong>Mean Nitrogen concentration does not differ among profiles</strong></p>
<p>Third <span class="math inline">\(H_{0}\)</span>: <strong>There is no interaction between site or profile in affecting Nitrogen concentration</strong></p>
<p>From the assumption checks output tables, is there any reason to be concerned about using the two-way ANOVA?</p>
<p><strong>There is no reason to reject the null hypothesis that data are normally distributed or variances are equal. We can proceed with the two-way ANOVA.</strong></p>
<p>Fill in Table 28.2 with the relevant information from the two-way ANOVA output.</p>
<table style="width:100%;">
<caption>Table 28.2: Two-way ANOVA output testing the effects of 2 sites and 3 different soil profiles on soil Nitrogen concentration in Angola.</caption>
<colgroup>
<col width="19%" />
<col width="21%" />
<col width="9%" />
<col width="20%" />
<col width="16%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Sum of Squares</th>
<th>df</th>
<th>Mean Square</th>
<th>F</th>
<th>p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Site</td>
<td><strong>21522.18384</strong></td>
<td><strong>1</strong></td>
<td><strong>21522.18384</strong></td>
<td><strong>12.03138</strong></td>
<td><strong>0.001</strong></td>
</tr>
<tr class="even">
<td>Profile</td>
<td><strong>22811.13680</strong></td>
<td><strong>2</strong></td>
<td><strong>11405.56840</strong></td>
<td><strong>6.37597</strong></td>
<td><strong>0.004</strong></td>
</tr>
<tr class="odd">
<td>Site * Profile</td>
<td><strong>16209.13035</strong></td>
<td><strong>2</strong></td>
<td><strong>8104.56517</strong></td>
<td><strong>4.53063</strong></td>
<td><strong>0.016</strong></td>
</tr>
<tr class="even">
<td>Residuals</td>
<td><strong>80497.68348</strong></td>
<td><strong>45</strong></td>
<td><strong>1788.83741</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>From this output table, should you reject or not reject your null hypotheses?</p>
<p>Reject First <span class="math inline">\(H_{0}\)</span>? <strong>Yes</strong>
Reject Second <span class="math inline">\(H_{0}\)</span>? <strong>Yes</strong>
Reject Third <span class="math inline">\(H_{0}\)</span>? <strong>Yes</strong></p>
<p><strong>It appears that Nitrogen concentration is different at different sites and across different profiles, and that there is an interaction between site and profile.</strong></p>
<p>Based on what you learned in Chapter 27 about interaction effects, what can you say about the interaction between Site and Profile? Does one Profile, in particular, appear to be causing the interaction to be significant? How can you infer this from the Estimated Marginal Means plot?</p>
<p><strong>We can see the interaction effects in the figure The middle profile, in particular, appears to be causing the interaction. Both lower and upper profiles are parallel. But the middle is clearly at a different slope than the other two, indicating an interaction effect.</strong></p>
<p>Based on the ANOVA output, what can you conclude?</p>
<p><strong>The two-way ANOVA shows that Site alone has a significant effect on Phosophorus. The Profile and Interaction terms are not significant.</strong></p>
</div>
</div>
<div id="chapter-31" class="section level2 hasAnchor" number="36.8">
<h2><span class="header-section-number">A.8</span> Chapter 31<a href="appendexA.html#chapter-31" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-31.1" class="section level3 hasAnchor" number="36.8.1">
<h3><span class="header-section-number">A.8.1</span> Exercise 31.1<a href="appendexA.html#exercise-31.1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>What are the null and alternative hypotheses for this Chi-square goodness of fit test?</p>
<p><span class="math inline">\(H_{O}\)</span>: <strong>There is no significant difference between expected and observed counts of living and dead bees.</strong></p>
<p><span class="math inline">\(H_{A}\)</span>: <strong>There is a significant difference between expected and observed counts of living and dead bees.</strong></p>
<p>What is the sample size (N) of the dataset? <strong>N: 256</strong></p>
<p>Based on this sample size, what are the expected counts for bees that survived and died?</p>
<p>Survived (<span class="math inline">\(E_{surv}\)</span>): <strong>128</strong></p>
<p>Died (<span class="math inline">\(E_{died}\)</span>): <strong>128</strong></p>
<p>Write down the observed counts of bees that survived and died.</p>
<p>Survived (<span class="math inline">\(O_{surv}\)</span>): <strong>139</strong></p>
<p>Died (<span class="math inline">\(O_{died}\)</span>): <strong>117</strong></p>
<p>What is the <span class="math inline">\(\chi^{2}\)</span> value? <strong>1.89</strong></p>
<p>How many degrees of freedom are there? <strong>df = 1</strong></p>
<p>Write these values below, and check to see if the <span class="math inline">\(\chi^{2}\)</span> and df match the values you calculated above by hand.</p>
<p><span class="math inline">\(\chi^{2}\)</span> = <strong>1.89063</strong></p>
<p>df = <strong>1</strong></p>
<p>P = <strong>0.16913</strong></p>
</div>
<div id="exercise-31.2" class="section level3 hasAnchor" number="36.8.2">
<h3><span class="header-section-number">A.8.2</span> Exercise 31.2<a href="appendexA.html#exercise-31.2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>What are the null and alternative hypotheses in this scenario?</p>
<p><span class="math inline">\(H_{O}\)</span>: <strong>There is no significant difference between expected and observed counts of colonies.</strong></p>
<p><span class="math inline">\(H_{A}\)</span>: <strong>There is a significant difference between expected and observed counts of colonies</strong></p>
<p>How many colonies are there in this dataset? <strong>8 colonies</strong></p>
<p>What is the output from the Goodness of Fit table?</p>
<p><span class="math inline">\(\chi^{2}\)</span> = <strong>3.5</strong></p>
<p>df = <strong>7</strong></p>
<p>P = <strong>0.83523</strong></p>
<p>From this output, what can you conclude about how bees were taken from the colonies?</p>
<p><strong>Bees appear to be taken from colonies in equal frequencies, i.e., with equal probability of sampling among colonies.</strong></p>
</div>
<div id="exercise-31.3" class="section level3 hasAnchor" number="36.8.3">
<h3><span class="header-section-number">A.8.3</span> Exercise 31.3<a href="appendexA.html#exercise-31.3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>What are the null and alternative hypotheses for this test of association?</p>
<p><span class="math inline">\(H_{O}\)</span>: <strong>There is no association between bee colony and bee survival.</strong>
<span class="math inline">\(H_{A}\)</span>: <strong>There is an association between bee colony and bee survival.</strong></p>
<p>Report the key statistics in the output table below.</p>
<p>Chi-square: <strong>11.31033</strong></p>
<p>df: <strong>7</strong></p>
<p>p: <strong>0.12564</strong></p>
<p>From these statistics, should you reject or not reject the null hypothesis?</p>
<p><span class="math inline">\(H_{O}\)</span>: <strong>Do not reject null hypothesis</strong></p>
<p>What can you conclude from this test? Explain your conclusion as if you were reporting the results of the test to someone who was unfamiliar with statistical hypothesis testing.</p>
<p><strong>From the statistical analysis, it appears that there is a highly significant association between the level of radiation that bees experience and the frequency with which they survive versus do not survive.</strong></p>
<p>Lastly, did the order which you placed the two variables matter? What if you switched Rows and Columns? In other words, put ‘survived’ in the Rows box and ‘radiation’ in the Columns box. Does this give you the same answer?</p>
<p><strong>The ordering of the two variables does not appear to matter. The Chi-square value and P values are the same.</strong></p>
</div>
<div id="exercise-31.4" class="section level3 hasAnchor" number="36.8.4">
<h3><span class="header-section-number">A.8.4</span> Exercise 31.4<a href="appendexA.html#exercise-31.4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Just looking at the scatterplot, does it appear as though bee mass and <span class="math inline">\(CO_{2}\)</span> output are correlated? Why or why not?</p>
<p><strong>The scatterplot might indicate a slight negative correlation, but it is difficult to say for sure just based on a visualisation.</strong></p>
<p>What are the null and alternative hypotheses of this test?</p>
<p><span class="math inline">\(H_{O}\)</span>: <strong>The correlation coefficient between bee mass and carbon dioxide output is zero.</strong></p>
<p><span class="math inline">\(H_{A}\)</span>: <strong>The correlation coefficient between bee mass and carbon dioxide output is negative.</strong></p>
<p>Check this box, then find the p-values for the Shapiro-Wilk test of normality in the panel to the right. Write these p-values down below.</p>
<p>Mass P = <strong>0.96248</strong></p>
<p><span class="math inline">\(CO_2\)</span> P = <strong>0.56459</strong></p>
<p>Based on these p-values, which type of correlation coefficient should we use to test <span class="math inline">\(H_{0}\)</span>, and why?</p>
<p><strong>We should use the Pearson’s product moment correlation coefficient because both variables appear to be normally distributed.</strong></p>
<p>This table reports both the correlation coefficient (here called “Pearson’s r”) and the p-value. Write these values below.</p>
<p>r: <strong>-0.18036</strong>
P: <strong>0.002</strong></p>
<p>Based on this output, what should we conclude about the association between bumblebee mass and carbon dioxide output?</p>
<p><strong>Bumblebee mass and carbon dioxide output are negatively correlated, meaning that as bumblebee mass increases, carbon dioxide output decreases.</strong></p>
</div>
<div id="exercise-31.5" class="section level3 hasAnchor" number="36.8.5">
<h3><span class="header-section-number">A.8.5</span> Exercise 31.5<a href="appendexA.html#exercise-31.5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>What are the null and alternative hypotheses of this test?</p>
<p><span class="math inline">\(H_{O}\)</span>: <strong>The correlation coefficient between bee mass and nectar consumption is zero.</strong>
<span class="math inline">\(H_{A}\)</span>: <strong>The correlation coefficient between bee mass and nectar consumption is not zero.</strong></p>
<p>Based on the output of these tests, what kind of correlation coefficient should we use for testing the null hypothesis? <strong>Spearman’s rank correlation coefficient</strong></p>
<p>What is the correlation coefficient and p-value from this test?</p>
<p>r = <strong>0.11954</strong>
P = <strong>0.05611</strong></p>
<p>Based on these results, should we reject or not reject the null hypothesis?</p>
<p><span class="math inline">\(H_{0}\)</span>: <strong>Do not reject null hypothesis</strong></p>
<p>Would we have made the same conclusion about the correlation (or lack thereof) between bee mass and nectar consumption? Why or why not?</p>
<p><strong>If we had used a Pearson product moment correlation coefficient instead of the Spearman’s rank correlation coefficient, we would have calculated r = 0.12729 and a p-value of P = 0.04186. Because our p-value would have been less than 0.05, we would have incorrectly rejected the null hypothesis.</strong></p>
</div>
</div>
<div id="chapter-34" class="section level2 hasAnchor" number="36.9">
<h2><span class="header-section-number">A.9</span> Chapter 34<a href="appendexA.html#chapter-34" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-34.1" class="section level3 hasAnchor" number="36.9.1">
<h3><span class="header-section-number">A.9.1</span> Exercise 34.1<a href="appendexA.html#exercise-34.1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Before doing this, what is the independent variable, and what is the dependent variable?</p>
<p>Independent variable: <strong>depth</strong></p>
<p>Dependent variable: <strong>PyC</strong></p>
<p>What is the sample size of this dataset? <strong>N = 240</strong></p>
<p>Describe the scatterplot that is produced in the jamovi panel to the right.</p>
<p><strong>Linear relationship with a lot of scatter. Perhaps a slight downward trend?</strong></p>
<p>In other words, does the scatterplot show any evidence of a curvilinear pattern in the data?</p>
<p><strong>The relationship appears to be linear.</strong></p>
<p>In other words, does the variance change along the range of the independent variable (i.e., the x-axis)?</p>
<p><strong>No evidence of heteroscedasticity, so this assumption appears to be valid.</strong></p>
<p>In your own words, what is this test doing? That is, what are we actually testing is or is not normally distributed? Drawing a picture might be helping to explain.</p>
<p><strong>This test is checking to see if the residual values around the regression line are normally distributed.</strong></p>
<p>What is the p-value of the Shapiro-Wilk test of normality? <strong>P = 0.91624</strong></p>
<p>Based on the above p-value, is it safe to conclude that the residuals are normally distributed? Conclusion: <strong>Yes, residual values are normally distributed.</strong></p>
<p>A new table will open up in the right panel called ‘Model Fit Measures’. Write the output statistics from this table below:</p>
<p><span class="math inline">\(R^{2}\)</span> = <strong>0.02532</strong></p>
<p>F: <strong>6.18319</strong></p>
<p>df1: <strong>1</strong></p>
<p>df2: <strong>238</strong></p>
<p>P: <strong>0.01358</strong></p>
<p>Based on these statistics, what percentage of the variation in pyrogenic carbon is explained by the linear regression model? <strong>2.532 per cent</strong></p>
<p>What null hypothesis does the p-value above test?</p>
<p><span class="math inline">\(H_{O}\)</span>: <strong>A model that includes depth is not a significantly better predictor of PyC than just the mean PyC.</strong></p>
<p>Do we reject or fail to reject <span class="math inline">\(H_{0}\)</span>? <strong>Reject <span class="math inline">\(H_{0}\)</span></strong></p>
<p>From this table, what are the coefficient estimates for the intercept and the slope (i.e., depth)?</p>
<p>Intercept: <strong>1.61719</strong></p>
<p>Slope: <strong>-0.00263</strong></p>
<p>What null hypotheses are we testing when inspecting these p-values?</p>
<p>Intercept <span class="math inline">\(H_{0}\)</span>: <strong>P &lt; 0.0001, testing null hypothesis that <span class="math inline">\(b_{0} = 0\)</span>.</strong></p>
<p>Slope <span class="math inline">\(H_{0}\)</span>: <strong>P = 0.01358, test null hypothesis that <span class="math inline">\(b_{1} = 0\)</span></strong></p>
<p>Finally, what can we conclude about the relationship between depth and pyrogenic carbon storage? <strong>Pyrogenic carbon changes with increasing soil depth.</strong></p>
</div>
<div id="exercise-34.2" class="section level3 hasAnchor" number="36.9.2">
<h3><span class="header-section-number">A.9.2</span> Exercise 34.2<a href="appendexA.html#exercise-34.2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Do all these assumptions appear to be met?</p>
<p>Linearity: <strong>No issues</strong></p>
<p>Normality: <strong>No issues</strong></p>
<p>Homoscedasticity: <strong>No issues</strong></p>
<p>Using the same protocol as the previous exercise, what percentage of the variation in PyC is explained by the regression model? <strong>Variation explained: 48.2 per cent (0.482 * 100% = 48.2%)</strong></p>
<p>Is the overall model statistically significant? How do you know? Model significance: <strong>Yes, because overall model test p-value is P &lt; 0.05</strong></p>
<p>Are the intercept and slope significantly different from zero?</p>
<p>Intercept: <strong>Yes, significantly different from zero; reject null hypothesis</strong></p>
<p>Slope: <strong>Yes, significantly different from zero; reject null hypothesis</strong></p>
<p>Write the intercept (<span class="math inline">\(b_{0}\)</span>) and slope (<span class="math inline">\(b_{1}\)</span>) of the regression below.</p>
<p><span class="math inline">\(b_{0}\)</span>: <strong>0.88911</strong></p>
<p><span class="math inline">\(b_{1}\)</span>: <strong>0.05688</strong></p>
<p>Using these values for the intercept and the slope, write the regression equation to predict pyrogenic carbon (PyC) from fire frequency (fire_freq).</p>
<p><strong>Y = 0.88911 + (0.05688 * X)</strong> OR <strong>PyC = 0.88911 + (0.05688 * fire_freq)</strong></p>
<p>Using this equation, what would be the predicted PyC for a location that had experienced 10 fires in the past 20 years (i.e., fire_freq = 10)? PyC = <strong>1.45791</strong></p>
<p>Explain what these 2 columns of data represent in terms of the scatterplot you made at the start of this exercise. In other words, where would the predicted and residual values be located on the scatterplot?</p>
<p><strong>The predicted values represent the PyC points that fall along the regression line for a particular fire_freq value. That is, what the model predicts PyC should be at each fire frequency. The residual values are the difference between the actual PyC values and what the predicted PyC values are in the model.</strong></p>
</div>
<div id="exercise-34.3" class="section level3 hasAnchor" number="36.9.3">
<h3><span class="header-section-number">A.9.3</span> Exercise 34.3<a href="appendexA.html#exercise-34.3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Write down what the independent and dependent variable(s) are for this regression.</p>
<p>Independent: <strong>Fire frequency and depth</strong></p>
<p>Dependent: <strong>Pyrogenic carbon</strong></p>
<p>Do all these assumptions appear to be met?</p>
<p>Linearity: <strong>Yes</strong></p>
<p>Normality: <strong>Yes</strong></p>
<p>Homoscedasticity: <strong>Yes</strong></p>
<p>Report these values from the Model Fit Measures output table below.</p>
<p><span class="math inline">\(R^{2}\)</span> = <strong>0.48202</strong></p>
<p>Adjusted <span class="math inline">\(R^{2}\)</span> = <strong>0.47765</strong></p>
<p>F = <strong>110.27348</strong></p>
<p><strong>P &lt; 0.0001</strong></p>
<p>Which one is most appropriate to use for interpreting the multiple regression?</p>
<p><strong>The adjusted R-squared takes into account that adding more independent variables will increase the total amount of variation explained in the dependent variable even if the independent variable is not a good predictor. We should therefore use the adjusted R-squared when looking at a multiple regression model.</strong></p>
<p>What is the null hypothesis of this tested with the F value and the P value shown in the Model Fit Measures table?</p>
<p><span class="math inline">\(H_{0}\)</span>: <strong>A model that includes the independent variables depth and fire frequency does not explain variation in PyC significantly better than just the mean of PyC.</strong></p>
<p>Based on the Overall Model Test output, should you reject or not reject <span class="math inline">\(H_{0}\)</span>? <strong>Reject the null hypothesis</strong></p>
<p>What can you conclude about the significance of the Intercept, and the partial regression coefficients for fire frequency and depth?</p>
<p><strong>The intercept and partial regression coefficient of fire frequency are significantly different from 0. But the partial regression coefficient of depth is not significantly different from 0.</strong></p>
<p>Using the partial regression coefficient estimates, fill in the equation below,</p>
<p>PyC = ( <strong>0.89456</strong> ) + ( <strong>0.05680</strong> )fire_freq + ( <strong>-0.00008</strong> )depth.</p>
<p>Next, use this to predict the pyrogenic carbon for a fire frequency of 12 and a depth of 60 cm.</p>
<p>PyC = <strong>1.57136</strong></p>
<p>Has the significance of soil depth as an independent variable changed? Based on what you know about the difference between simple linear regression and multiple regression, why might this be the case?</p>
<p><strong>Yes, the soil depth was significant by itself as a predictor of PyC in the simple linear regression of the first exercise. But in this multiple regression model the partial regression coefficient is not significant. This might be because when you consider depth in the context of fire frequency, the effect of depth by itself is not significant. Once you account for fire frequency, depth no longer is a meaningful predictor of PyC. If you hold fire frequency constant in a model, then depth by itself does not affect PyC.</strong></p>
</div>
<div id="exercise-34.4" class="section level3 hasAnchor" number="36.9.4">
<h3><span class="header-section-number">A.9.4</span> Exercise 34.4<a href="appendexA.html#exercise-34.4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<caption>Table 34.1: Model Coefficients output table for a multiple regression model predicting pyrogenic carbon from soil depth, fire frequency, and soil pH in Gabon.</caption>
<colgroup>
<col width="18%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Estimate</th>
<th>Std. Error</th>
<th>t value</th>
<th>Pr(&gt;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td><strong>0.98892</strong></td>
<td><strong>0.34591</strong></td>
<td><strong>2.85888</strong></td>
<td><strong>0.00463</strong></td>
</tr>
<tr class="even">
<td>depth</td>
<td><strong>-0.00006</strong></td>
<td><strong>8e-04</strong></td>
<td><strong>-0.07411</strong></td>
<td><strong>0.94098</strong></td>
</tr>
<tr class="odd">
<td>fire_freq</td>
<td><strong>0.05679</strong></td>
<td><strong>0.00394</strong></td>
<td><strong>14.42303</strong></td>
<td><strong>&lt;0.00001</strong></td>
</tr>
<tr class="even">
<td>pH</td>
<td><strong>-0.01584</strong></td>
<td><strong>0.05679</strong></td>
<td><strong>-0.27886</strong></td>
<td><strong>0.78059</strong></td>
</tr>
</tbody>
</table>
<p>From the Model Fit Measures table, what is the <span class="math inline">\(R^{2}\)</span> and Adjusted <span class="math inline">\(R^{2}\)</span> of this model?</p>
<p><span class="math inline">\(R^{2}\)</span> = <strong>0.48219</strong></p>
<p>Adjusted <span class="math inline">\(R^{2}\)</span> = <strong>0.47561</strong></p>
<p>Is the <span class="math inline">\(R^{2}\)</span> value of this model higher or lower than the multiple regression model without pH?</p>
<p><strong>The model without pH had an <span class="math inline">\(R^{2}\)</span> = 0.48202, so it was lower without pH.</strong></p>
<p>Is the Adjusted <span class="math inline">\(R^{2}\)</span> value of this model higher or lower than the multiple regression model without pH?</p>
<p><strong>The model without pH had an Adjusted <span class="math inline">\(R^{2}\)</span> = 0.47765, so it was higher without pH</strong></p>
<p>Based on what you know from Chapter 33.1, explain why the <span class="math inline">\(R^{2}\)</span> and Adjusted <span class="math inline">\(R^{2}\)</span> might have changed in different directions with the addition of a new independent variable.</p>
<p><strong>The <span class="math inline">\(R^{2}\)</span> just tells us how much variation is the dependent variable is explained by the model, but there is no penalty for adding more independent variables to the model. Consequently, adding the additional independent variable (pH) can only increase (or at least not decrease) the amount of variation explained. In contrast, the adjusted <span class="math inline">\(R^{2}\)</span> penalises the R2 for each additional independent variable in the model, so because we have added the independent variable pH, our adjusted <span class="math inline">\(R^{2}\)</span> can go down.</strong></p>
<p>Finally, use the equation of this new model to predict PyC for a soil sample at a depth of 0, fire frequency of 0, and pH of 6.</p>
<p><strong>PyC = 0.98892 - (0.00006<em>0) + (0.05679 </em> 0) - (0.01584 * 6)</strong></p>
<p><strong>PyC = 0.89388</strong></p>
</div>
<div id="exercise-33.5" class="section level3 hasAnchor" number="36.9.5">
<h3><span class="header-section-number">A.9.5</span> Exercise 33.5<a href="appendexA.html#exercise-33.5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>What assumption(s) appear as though they might be violated for this simple regression? Explain how you figured this out.</p>
<p><strong>It appears that the assumptions of normality and homoscedasticity are violated. We found this out by running a Shapiro-Wilk test and rejecting the null hypothesis that data are normally distributed, and by using a scatterplot to visualise how the variation in temperature changed along the range of fire frequency.</strong></p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chapter_35.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="uncertainty_derivation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/10-Appendix.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
