<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Measures of spread | Fundamental statistical concepts and techniques in the biological and environmental sciences: With jamovi</title>
  <meta name="description" content="This is an introductory statistics textbook for students in the biological and environmental sciences with examples using jamovi statistical software." />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Measures of spread | Fundamental statistical concepts and techniques in the biological and environmental sciences: With jamovi" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is an introductory statistics textbook for students in the biological and environmental sciences with examples using jamovi statistical software." />
  <meta name="github-repo" content="bradduthie/statistics_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Measures of spread | Fundamental statistical concepts and techniques in the biological and environmental sciences: With jamovi" />
  
  <meta name="twitter:description" content="This is an introductory statistics textbook for students in the biological and environmental sciences with examples using jamovi statistical software." />
  

<meta name="author" content="A. Bradley Duthie" />


<meta name="date" content="2024-03-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chapter_11.html"/>
<link rel="next" href="Chapter_13.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { font-weight: bold; } /* Alert */
code span.an { font-style: italic; } /* Annotation */
code span.cf { font-weight: bold; } /* ControlFlow */
code span.co { font-style: italic; } /* Comment */
code span.cv { font-style: italic; } /* CommentVar */
code span.do { font-style: italic; } /* Documentation */
code span.dt { text-decoration: underline; } /* DataType */
code span.er { font-weight: bold; } /* Error */
code span.in { font-style: italic; } /* Information */
code span.kw { font-weight: bold; } /* Keyword */
code span.pp { font-weight: bold; } /* Preprocessor */
code span.wa { font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics with jamovi</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure"><i class="fa fa-check"></i>How this book is structured</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#datasets"><i class="fa fa-check"></i>Datasets used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#author"><i class="fa fa-check"></i>About the author</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chapter_1.html"><a href="Chapter_1.html"><i class="fa fa-check"></i><b>1</b> Background mathematics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="Chapter_1.html"><a href="Chapter_1.html#numbers-and-operations"><i class="fa fa-check"></i><b>1.1</b> Numbers and operations</a></li>
<li class="chapter" data-level="1.2" data-path="Chapter_1.html"><a href="Chapter_1.html#logarithms"><i class="fa fa-check"></i><b>1.2</b> Logarithms</a></li>
<li class="chapter" data-level="1.3" data-path="Chapter_1.html"><a href="Chapter_1.html#order-of-operations"><i class="fa fa-check"></i><b>1.3</b> Order of operations</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chapter_2.html"><a href="Chapter_2.html"><i class="fa fa-check"></i><b>2</b> Data organisation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="Chapter_2.html"><a href="Chapter_2.html#tidy-data"><i class="fa fa-check"></i><b>2.1</b> Tidy data</a></li>
<li class="chapter" data-level="2.2" data-path="Chapter_2.html"><a href="Chapter_2.html#data-files"><i class="fa fa-check"></i><b>2.2</b> Data files</a></li>
<li class="chapter" data-level="2.3" data-path="Chapter_2.html"><a href="Chapter_2.html#managing-data-files"><i class="fa fa-check"></i><b>2.3</b> Managing data files</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chapter_3.html"><a href="Chapter_3.html"><i class="fa fa-check"></i><b>3</b> <em>Practical</em>. Preparing data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-1-transferring-data-to-a-spreadsheet"><i class="fa fa-check"></i><b>3.1</b> Exercise 1: Transferring data to a spreadsheet</a></li>
<li class="chapter" data-level="3.2" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-2-making-spreadsheet-data-tidy"><i class="fa fa-check"></i><b>3.2</b> Exercise 2: Making spreadsheet data tidy</a></li>
<li class="chapter" data-level="3.3" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-3-making-data-tidy-again"><i class="fa fa-check"></i><b>3.3</b> Exercise 3: Making data tidy again</a></li>
<li class="chapter" data-level="3.4" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-4-tidy-data-and-spreadsheet-calculations"><i class="fa fa-check"></i><b>3.4</b> Exercise 4: Tidy data and spreadsheet calculations</a></li>
<li class="chapter" data-level="3.5" data-path="Chapter_3.html"><a href="Chapter_3.html#summary"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chapter_4.html"><a href="Chapter_4.html"><i class="fa fa-check"></i><b>4</b> Populations and samples</a></li>
<li class="chapter" data-level="5" data-path="Chapter_5.html"><a href="Chapter_5.html"><i class="fa fa-check"></i><b>5</b> Types of variables</a></li>
<li class="chapter" data-level="6" data-path="Chapter_6.html"><a href="Chapter_6.html"><i class="fa fa-check"></i><b>6</b> Accuracy, precision, and units</a>
<ul>
<li class="chapter" data-level="6.1" data-path="Chapter_6.html"><a href="Chapter_6.html#accuracy"><i class="fa fa-check"></i><b>6.1</b> Accuracy</a></li>
<li class="chapter" data-level="6.2" data-path="Chapter_6.html"><a href="Chapter_6.html#precision"><i class="fa fa-check"></i><b>6.2</b> Precision</a></li>
<li class="chapter" data-level="6.3" data-path="Chapter_6.html"><a href="Chapter_6.html#systems-of-units"><i class="fa fa-check"></i><b>6.3</b> Systems of units</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chapter_7.html"><a href="Chapter_7.html"><i class="fa fa-check"></i><b>7</b> Uncertainty propagation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="Chapter_7.html"><a href="Chapter_7.html#adding-or-subtracting-errors"><i class="fa fa-check"></i><b>7.1</b> Adding or subtracting errors</a></li>
<li class="chapter" data-level="7.2" data-path="Chapter_7.html"><a href="Chapter_7.html#multiplying-or-dividing-errors"><i class="fa fa-check"></i><b>7.2</b> Multiplying or dividing errors</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chapter_8.html"><a href="Chapter_8.html"><i class="fa fa-check"></i><b>8</b> <em>Practical</em>. Introduction to jamovi</a>
<ul>
<li class="chapter" data-level="8.1" data-path="Chapter_8.html"><a href="Chapter_8.html#summary_statistics_02"><i class="fa fa-check"></i><b>8.1</b> Exercise for summary statistics</a></li>
<li class="chapter" data-level="8.2" data-path="Chapter_8.html"><a href="Chapter_8.html#transforming_variables_02"><i class="fa fa-check"></i><b>8.2</b> Exercise on transforming variables</a></li>
<li class="chapter" data-level="8.3" data-path="Chapter_8.html"><a href="Chapter_8.html#computing_variables_02"><i class="fa fa-check"></i><b>8.3</b> Exercise on computing variables</a></li>
<li class="chapter" data-level="8.4" data-path="Chapter_8.html"><a href="Chapter_8.html#summary-1"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chapter_9.html"><a href="Chapter_9.html"><i class="fa fa-check"></i><b>9</b> Decimal places, significant figures, and rounding</a>
<ul>
<li class="chapter" data-level="9.1" data-path="Chapter_9.html"><a href="Chapter_9.html#decimal-places-and-significant-figures"><i class="fa fa-check"></i><b>9.1</b> Decimal places and significant figures</a></li>
<li class="chapter" data-level="9.2" data-path="Chapter_9.html"><a href="Chapter_9.html#rounding"><i class="fa fa-check"></i><b>9.2</b> Rounding</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chapter_10.html"><a href="Chapter_10.html"><i class="fa fa-check"></i><b>10</b> Graphs</a>
<ul>
<li class="chapter" data-level="10.1" data-path="Chapter_10.html"><a href="Chapter_10.html#histograms"><i class="fa fa-check"></i><b>10.1</b> Histograms</a></li>
<li class="chapter" data-level="10.2" data-path="Chapter_10.html"><a href="Chapter_10.html#barplots-and-pie-charts"><i class="fa fa-check"></i><b>10.2</b> Barplots and pie charts</a></li>
<li class="chapter" data-level="10.3" data-path="Chapter_10.html"><a href="Chapter_10.html#box-whisker-plots"><i class="fa fa-check"></i><b>10.3</b> Box-whisker plots</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chapter_11.html"><a href="Chapter_11.html"><i class="fa fa-check"></i><b>11</b> Measures of central tendency</a>
<ul>
<li class="chapter" data-level="11.1" data-path="Chapter_11.html"><a href="Chapter_11.html#the-mean"><i class="fa fa-check"></i><b>11.1</b> The mean</a></li>
<li class="chapter" data-level="11.2" data-path="Chapter_11.html"><a href="Chapter_11.html#the-mode"><i class="fa fa-check"></i><b>11.2</b> The mode</a></li>
<li class="chapter" data-level="11.3" data-path="Chapter_11.html"><a href="Chapter_11.html#the-median-and-quantiles"><i class="fa fa-check"></i><b>11.3</b> The median and quantiles</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chapter_12.html"><a href="Chapter_12.html"><i class="fa fa-check"></i><b>12</b> Measures of spread</a>
<ul>
<li class="chapter" data-level="12.1" data-path="Chapter_12.html"><a href="Chapter_12.html#the-range"><i class="fa fa-check"></i><b>12.1</b> The range</a></li>
<li class="chapter" data-level="12.2" data-path="Chapter_12.html"><a href="Chapter_12.html#the-inter-quartile-range"><i class="fa fa-check"></i><b>12.2</b> The inter-quartile range</a></li>
<li class="chapter" data-level="12.3" data-path="Chapter_12.html"><a href="Chapter_12.html#the-variance"><i class="fa fa-check"></i><b>12.3</b> The variance</a></li>
<li class="chapter" data-level="12.4" data-path="Chapter_12.html"><a href="Chapter_12.html#the-standard-deviation"><i class="fa fa-check"></i><b>12.4</b> The standard deviation</a></li>
<li class="chapter" data-level="12.5" data-path="Chapter_12.html"><a href="Chapter_12.html#the-coefficient-of-variation"><i class="fa fa-check"></i><b>12.5</b> The coefficient of variation</a></li>
<li class="chapter" data-level="12.6" data-path="Chapter_12.html"><a href="Chapter_12.html#the-standard-error"><i class="fa fa-check"></i><b>12.6</b> The standard error</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chapter_13.html"><a href="Chapter_13.html"><i class="fa fa-check"></i><b>13</b> Skew and Kurtosis</a>
<ul>
<li class="chapter" data-level="13.1" data-path="Chapter_13.html"><a href="Chapter_13.html#skew"><i class="fa fa-check"></i><b>13.1</b> Skew</a></li>
<li class="chapter" data-level="13.2" data-path="Chapter_13.html"><a href="Chapter_13.html#kurtosis"><i class="fa fa-check"></i><b>13.2</b> Kurtosis</a></li>
<li class="chapter" data-level="13.3" data-path="Chapter_13.html"><a href="Chapter_13.html#moments"><i class="fa fa-check"></i><b>13.3</b> Moments</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chapter_14.html"><a href="Chapter_14.html"><i class="fa fa-check"></i><b>14</b> <em>Practical</em>. Plotting and statistical summaries in jamovi</a>
<ul>
<li class="chapter" data-level="14.1" data-path="Chapter_14.html"><a href="Chapter_14.html#reorganise-the-dataset-into-a-tidy-format"><i class="fa fa-check"></i><b>14.1</b> Reorganise the dataset into a tidy format</a></li>
<li class="chapter" data-level="14.2" data-path="Chapter_14.html"><a href="Chapter_14.html#histograms-and-box-whisker-plots"><i class="fa fa-check"></i><b>14.2</b> Histograms and box-whisker plots</a></li>
<li class="chapter" data-level="14.3" data-path="Chapter_14.html"><a href="Chapter_14.html#calculate-summary-statistics"><i class="fa fa-check"></i><b>14.3</b> Calculate summary statistics</a></li>
<li class="chapter" data-level="14.4" data-path="Chapter_14.html"><a href="Chapter_14.html#reporting-decimals-and-significant-figures"><i class="fa fa-check"></i><b>14.4</b> Reporting decimals and significant figures</a></li>
<li class="chapter" data-level="14.5" data-path="Chapter_14.html"><a href="Chapter_14.html#comparing-across-sites"><i class="fa fa-check"></i><b>14.5</b> Comparing across sites</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="Chapter_15.html"><a href="Chapter_15.html"><i class="fa fa-check"></i><b>15</b> Introduction to probability models</a>
<ul>
<li class="chapter" data-level="15.1" data-path="Chapter_15.html"><a href="Chapter_15.html#an-instructive-example"><i class="fa fa-check"></i><b>15.1</b> An instructive example</a></li>
<li class="chapter" data-level="15.2" data-path="Chapter_15.html"><a href="Chapter_15.html#biological-applications"><i class="fa fa-check"></i><b>15.2</b> Biological applications</a></li>
<li class="chapter" data-level="15.3" data-path="Chapter_15.html"><a href="Chapter_15.html#sampling-with-and-without-replacement"><i class="fa fa-check"></i><b>15.3</b> Sampling with and without replacement</a></li>
<li class="chapter" data-level="15.4" data-path="Chapter_15.html"><a href="Chapter_15.html#probability-distributions"><i class="fa fa-check"></i><b>15.4</b> Probability distributions</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="Chapter_15.html"><a href="Chapter_15.html#binomial-distribution"><i class="fa fa-check"></i><b>15.4.1</b> Binomial distribution</a></li>
<li class="chapter" data-level="15.4.2" data-path="Chapter_15.html"><a href="Chapter_15.html#poisson-distribution"><i class="fa fa-check"></i><b>15.4.2</b> Poisson distribution</a></li>
<li class="chapter" data-level="15.4.3" data-path="Chapter_15.html"><a href="Chapter_15.html#uniform-distribution"><i class="fa fa-check"></i><b>15.4.3</b> Uniform distribution</a></li>
<li class="chapter" data-level="15.4.4" data-path="Chapter_15.html"><a href="Chapter_15.html#normal-distribution"><i class="fa fa-check"></i><b>15.4.4</b> Normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="Chapter_15.html"><a href="Chapter_15.html#summary-2"><i class="fa fa-check"></i><b>15.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="Chapter_16.html"><a href="Chapter_16.html"><i class="fa fa-check"></i><b>16</b> The Central Limit Theorem (CLT)</a>
<ul>
<li class="chapter" data-level="16.1" data-path="Chapter_16.html"><a href="Chapter_16.html#the-distribution-of-means-is-normal"><i class="fa fa-check"></i><b>16.1</b> The distribution of means is normal</a></li>
<li class="chapter" data-level="16.2" data-path="Chapter_16.html"><a href="Chapter_16.html#probability-and-z-scores"><i class="fa fa-check"></i><b>16.2</b> Probability and z-scores</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="Chapter_17.html"><a href="Chapter_17.html"><i class="fa fa-check"></i><b>17</b> <em>Practical</em>. Probability and simulation</a>
<ul>
<li class="chapter" data-level="17.1" data-path="Chapter_17.html"><a href="Chapter_17.html#probabilities-from-a-dataset"><i class="fa fa-check"></i><b>17.1</b> Probabilities from a dataset</a></li>
<li class="chapter" data-level="17.2" data-path="Chapter_17.html"><a href="Chapter_17.html#probabilities-from-a-normal-distribution"><i class="fa fa-check"></i><b>17.2</b> Probabilities from a normal distribution</a></li>
<li class="chapter" data-level="17.3" data-path="Chapter_17.html"><a href="Chapter_17.html#central-limit-theorem"><i class="fa fa-check"></i><b>17.3</b> Central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="Chapter_18.html"><a href="Chapter_18.html"><i class="fa fa-check"></i><b>18</b> Confidence intervals (CIs)</a>
<ul>
<li class="chapter" data-level="18.1" data-path="Chapter_18.html"><a href="Chapter_18.html#normal-distribution-cis"><i class="fa fa-check"></i><b>18.1</b> Normal distribution CIs</a></li>
<li class="chapter" data-level="18.2" data-path="Chapter_18.html"><a href="Chapter_18.html#binomial-distribution-cis"><i class="fa fa-check"></i><b>18.2</b> Binomial distribution CIs</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="Chapter_19.html"><a href="Chapter_19.html"><i class="fa fa-check"></i><b>19</b> The t-interval</a></li>
<li class="chapter" data-level="20" data-path="Chapter_20.html"><a href="Chapter_20.html"><i class="fa fa-check"></i><b>20</b> <em>Practical</em>. z- and t- intervals</a>
<ul>
<li class="chapter" data-level="20.1" data-path="Chapter_20.html"><a href="Chapter_20.html#confidence-intervals-with-distraction"><i class="fa fa-check"></i><b>20.1</b> Confidence intervals with distrACTION</a></li>
<li class="chapter" data-level="20.2" data-path="Chapter_20.html"><a href="Chapter_20.html#confidence-intervals-from-z--and-t-scores"><i class="fa fa-check"></i><b>20.2</b> Confidence intervals from z- and t-scores</a></li>
<li class="chapter" data-level="20.3" data-path="Chapter_20.html"><a href="Chapter_20.html#confidence-intervals-for-different-sample-sizes-t--and-z-"><i class="fa fa-check"></i><b>20.3</b> Confidence intervals for different sample sizes (t- and z-)</a></li>
<li class="chapter" data-level="20.4" data-path="Chapter_20.html"><a href="Chapter_20.html#proportion-confidence-intervals"><i class="fa fa-check"></i><b>20.4</b> Proportion confidence intervals</a></li>
<li class="chapter" data-level="20.5" data-path="Chapter_20.html"><a href="Chapter_20.html#another-proportion-confidence-interval"><i class="fa fa-check"></i><b>20.5</b> Another proportion confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="Chapter_21.html"><a href="Chapter_21.html"><i class="fa fa-check"></i><b>21</b> What is hypothesis testing?</a>
<ul>
<li class="chapter" data-level="21.1" data-path="Chapter_21.html"><a href="Chapter_21.html#how-ridiculous-is-our-hypothesis"><i class="fa fa-check"></i><b>21.1</b> How ridiculous is our hypothesis?</a></li>
<li class="chapter" data-level="21.2" data-path="Chapter_21.html"><a href="Chapter_21.html#statistical-hypothesis-testing"><i class="fa fa-check"></i><b>21.2</b> Statistical hypothesis testing</a></li>
<li class="chapter" data-level="21.3" data-path="Chapter_21.html"><a href="Chapter_21.html#p-values-false-positives-and-power"><i class="fa fa-check"></i><b>21.3</b> P-values, false positives, and power</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="Chapter_22.html"><a href="Chapter_22.html"><i class="fa fa-check"></i><b>22</b> The t-test</a>
<ul>
<li class="chapter" data-level="22.1" data-path="Chapter_22.html"><a href="Chapter_22.html#one-sample-t-test"><i class="fa fa-check"></i><b>22.1</b> One sample t-test</a></li>
<li class="chapter" data-level="22.2" data-path="Chapter_22.html"><a href="Chapter_22.html#independent-samples-t-test"><i class="fa fa-check"></i><b>22.2</b> Independent samples t-test</a></li>
<li class="chapter" data-level="22.3" data-path="Chapter_22.html"><a href="Chapter_22.html#paired-samples-t-test"><i class="fa fa-check"></i><b>22.3</b> Paired samples t-test</a></li>
<li class="chapter" data-level="22.4" data-path="Chapter_22.html"><a href="Chapter_22.html#assumptions-of-t-tests"><i class="fa fa-check"></i><b>22.4</b> Assumptions of t-tests</a></li>
<li class="chapter" data-level="22.5" data-path="Chapter_22.html"><a href="Chapter_22.html#non-parametric-alternatives"><i class="fa fa-check"></i><b>22.5</b> Non-parametric alternatives</a>
<ul>
<li class="chapter" data-level="22.5.1" data-path="Chapter_22.html"><a href="Chapter_22.html#wilcoxon-test"><i class="fa fa-check"></i><b>22.5.1</b> Wilcoxon test</a></li>
<li class="chapter" data-level="22.5.2" data-path="Chapter_22.html"><a href="Chapter_22.html#mann-whitney-u-test"><i class="fa fa-check"></i><b>22.5.2</b> Mann-Whitney U test</a></li>
</ul></li>
<li class="chapter" data-level="22.6" data-path="Chapter_22.html"><a href="Chapter_22.html#summary-3"><i class="fa fa-check"></i><b>22.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="Chapter_23.html"><a href="Chapter_23.html"><i class="fa fa-check"></i><b>23</b> <em>Practical</em>. Hypothesis testing and t-tests</a>
<ul>
<li class="chapter" data-level="23.1" data-path="Chapter_23.html"><a href="Chapter_23.html#exercise-on-a-simple-one-sample-t-test"><i class="fa fa-check"></i><b>23.1</b> Exercise on a simple one sample t-test</a></li>
<li class="chapter" data-level="23.2" data-path="Chapter_23.html"><a href="Chapter_23.html#exercise-on-a-paired-t-test"><i class="fa fa-check"></i><b>23.2</b> Exercise on a paired t-test</a></li>
<li class="chapter" data-level="23.3" data-path="Chapter_23.html"><a href="Chapter_23.html#wilcoxon-test-1"><i class="fa fa-check"></i><b>23.3</b> Wilcoxon test</a></li>
<li class="chapter" data-level="23.4" data-path="Chapter_23.html"><a href="Chapter_23.html#independent-samples-t-test-1"><i class="fa fa-check"></i><b>23.4</b> Independent samples t-test</a></li>
<li class="chapter" data-level="23.5" data-path="Chapter_23.html"><a href="Chapter_23.html#mann-whitney-u-test-1"><i class="fa fa-check"></i><b>23.5</b> Mann-Whitney U Test</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="Chapter_24.html"><a href="Chapter_24.html"><i class="fa fa-check"></i><b>24</b> Analysis of variance</a>
<ul>
<li class="chapter" data-level="24.1" data-path="Chapter_24.html"><a href="Chapter_24.html#the-f-distribution"><i class="fa fa-check"></i><b>24.1</b> The F-distribution</a></li>
<li class="chapter" data-level="24.2" data-path="Chapter_24.html"><a href="Chapter_24.html#one-way-anova"><i class="fa fa-check"></i><b>24.2</b> One-way ANOVA</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="Chapter_24.html"><a href="Chapter_24.html#anova-mean-variance-among-groups"><i class="fa fa-check"></i><b>24.2.1</b> ANOVA mean variance among groups</a></li>
<li class="chapter" data-level="24.2.2" data-path="Chapter_24.html"><a href="Chapter_24.html#anova-mean-variance-within-groups"><i class="fa fa-check"></i><b>24.2.2</b> ANOVA mean variance within groups</a></li>
<li class="chapter" data-level="24.2.3" data-path="Chapter_24.html"><a href="Chapter_24.html#anova-f-statistic-calculation"><i class="fa fa-check"></i><b>24.2.3</b> ANOVA F-statistic calculation</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="Chapter_24.html"><a href="Chapter_24.html#assumptions-of-anova"><i class="fa fa-check"></i><b>24.3</b> Assumptions of ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="Chapter_25.html"><a href="Chapter_25.html"><i class="fa fa-check"></i><b>25</b> Multiple comparisons</a></li>
<li class="chapter" data-level="26" data-path="Chapter_26.html"><a href="Chapter_26.html"><i class="fa fa-check"></i><b>26</b> Kruskall-Wallis H test</a></li>
<li class="chapter" data-level="27" data-path="Chapter_27.html"><a href="Chapter_27.html"><i class="fa fa-check"></i><b>27</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="28" data-path="Chapter_28.html"><a href="Chapter_28.html"><i class="fa fa-check"></i><b>28</b> <em>Practical</em>. ANOVA and associated tests</a>
<ul>
<li class="chapter" data-level="28.1" data-path="Chapter_28.html"><a href="Chapter_28.html#one-way-anova-site"><i class="fa fa-check"></i><b>28.1</b> One-way ANOVA (site)</a></li>
<li class="chapter" data-level="28.2" data-path="Chapter_28.html"><a href="Chapter_28.html#one-way-anova-profile"><i class="fa fa-check"></i><b>28.2</b> One-way ANOVA (profile)</a></li>
<li class="chapter" data-level="28.3" data-path="Chapter_28.html"><a href="Chapter_28.html#multiple-comparisons"><i class="fa fa-check"></i><b>28.3</b> Multiple comparisons</a></li>
<li class="chapter" data-level="28.4" data-path="Chapter_28.html"><a href="Chapter_28.html#kruskall-wallis-h-test"><i class="fa fa-check"></i><b>28.4</b> Kruskall-Wallis H test</a></li>
<li class="chapter" data-level="28.5" data-path="Chapter_28.html"><a href="Chapter_28.html#two-way-anova"><i class="fa fa-check"></i><b>28.5</b> Two-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="Chapter_29.html"><a href="Chapter_29.html"><i class="fa fa-check"></i><b>29</b> Frequency and count data</a>
<ul>
<li class="chapter" data-level="29.1" data-path="Chapter_29.html"><a href="Chapter_29.html#the-chi-square-distribution"><i class="fa fa-check"></i><b>29.1</b> The Chi-square distribution</a></li>
<li class="chapter" data-level="29.2" data-path="Chapter_29.html"><a href="Chapter_29.html#chi-square-goodness-of-fit"><i class="fa fa-check"></i><b>29.2</b> Chi-square goodness of fit</a></li>
<li class="chapter" data-level="29.3" data-path="Chapter_29.html"><a href="Chapter_29.html#chi-square-test-of-association"><i class="fa fa-check"></i><b>29.3</b> Chi-square test of association</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="Chapter_30.html"><a href="Chapter_30.html"><i class="fa fa-check"></i><b>30</b> Correlation</a>
<ul>
<li class="chapter" data-level="30.1" data-path="Chapter_30.html"><a href="Chapter_30.html#scatterplots"><i class="fa fa-check"></i><b>30.1</b> Scatterplots</a></li>
<li class="chapter" data-level="30.2" data-path="Chapter_30.html"><a href="Chapter_30.html#the-correlation-coefficient"><i class="fa fa-check"></i><b>30.2</b> The correlation coefficient</a>
<ul>
<li class="chapter" data-level="30.2.1" data-path="Chapter_30.html"><a href="Chapter_30.html#pearson-product-moment-correlation-coefficient"><i class="fa fa-check"></i><b>30.2.1</b> Pearson product moment correlation coefficient</a></li>
<li class="chapter" data-level="30.2.2" data-path="Chapter_30.html"><a href="Chapter_30.html#spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>30.2.2</b> Spearman’s rank correlation coefficient</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="Chapter_30.html"><a href="Chapter_30.html#correlation-hypothesis-testing"><i class="fa fa-check"></i><b>30.3</b> Correlation hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="Chapter_31.html"><a href="Chapter_31.html"><i class="fa fa-check"></i><b>31</b> <em>Practical</em>. Analysis of counts and correlations</a>
<ul>
<li class="chapter" data-level="31.1" data-path="Chapter_31.html"><a href="Chapter_31.html#survival-goodness-of-fit"><i class="fa fa-check"></i><b>31.1</b> Survival goodness of fit</a></li>
<li class="chapter" data-level="31.2" data-path="Chapter_31.html"><a href="Chapter_31.html#colony-goodness-of-fit"><i class="fa fa-check"></i><b>31.2</b> Colony goodness of fit</a></li>
<li class="chapter" data-level="31.3" data-path="Chapter_31.html"><a href="Chapter_31.html#chi-square-test-of-association-1"><i class="fa fa-check"></i><b>31.3</b> Chi-Square test of association</a></li>
<li class="chapter" data-level="31.4" data-path="Chapter_31.html"><a href="Chapter_31.html#pearson-product-moment-correlation-test"><i class="fa fa-check"></i><b>31.4</b> Pearson product moment correlation test</a></li>
<li class="chapter" data-level="31.5" data-path="Chapter_31.html"><a href="Chapter_31.html#spearmans-rank-correlation-test"><i class="fa fa-check"></i><b>31.5</b> Spearman’s rank correlation test</a></li>
<li class="chapter" data-level="31.6" data-path="Chapter_31.html"><a href="Chapter_31.html#untidy-goodness-of-fit"><i class="fa fa-check"></i><b>31.6</b> Untidy goodness of fit</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="Chapter_32.html"><a href="Chapter_32.html"><i class="fa fa-check"></i><b>32</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="32.1" data-path="Chapter_32.html"><a href="Chapter_32.html#visual-interpretation-of-regression"><i class="fa fa-check"></i><b>32.1</b> Visual interpretation of regression</a></li>
<li class="chapter" data-level="32.2" data-path="Chapter_32.html"><a href="Chapter_32.html#intercepts-slopes-and-residuals"><i class="fa fa-check"></i><b>32.2</b> Intercepts, slopes, and residuals</a></li>
<li class="chapter" data-level="32.3" data-path="Chapter_32.html"><a href="Chapter_32.html#regression-coefficients"><i class="fa fa-check"></i><b>32.3</b> Regression coefficients</a></li>
<li class="chapter" data-level="32.4" data-path="Chapter_32.html"><a href="Chapter_32.html#regression-line-calculation"><i class="fa fa-check"></i><b>32.4</b> Regression line calculation</a></li>
<li class="chapter" data-level="32.5" data-path="Chapter_32.html"><a href="Chapter_32.html#coefficient-of-determination"><i class="fa fa-check"></i><b>32.5</b> Coefficient of determination</a></li>
<li class="chapter" data-level="32.6" data-path="Chapter_32.html"><a href="Chapter_32.html#regression-assumptions"><i class="fa fa-check"></i><b>32.6</b> Regression assumptions</a></li>
<li class="chapter" data-level="32.7" data-path="Chapter_32.html"><a href="Chapter_32.html#regression-hypothesis-testing"><i class="fa fa-check"></i><b>32.7</b> Regression hypothesis testing</a>
<ul>
<li class="chapter" data-level="32.7.1" data-path="Chapter_32.html"><a href="Chapter_32.html#overall-model-significance"><i class="fa fa-check"></i><b>32.7.1</b> Overall model significance</a></li>
<li class="chapter" data-level="32.7.2" data-path="Chapter_32.html"><a href="Chapter_32.html#significance-of-the-intercept"><i class="fa fa-check"></i><b>32.7.2</b> Significance of the intercept</a></li>
<li class="chapter" data-level="32.7.3" data-path="Chapter_32.html"><a href="Chapter_32.html#significance-of-the-slope"><i class="fa fa-check"></i><b>32.7.3</b> Significance of the slope</a></li>
<li class="chapter" data-level="32.7.4" data-path="Chapter_32.html"><a href="Chapter_32.html#simple-regression-output"><i class="fa fa-check"></i><b>32.7.4</b> Simple regression output</a></li>
</ul></li>
<li class="chapter" data-level="32.8" data-path="Chapter_32.html"><a href="Chapter_32.html#prediction-with-linear-models"><i class="fa fa-check"></i><b>32.8</b> Prediction with linear models</a></li>
<li class="chapter" data-level="32.9" data-path="Chapter_32.html"><a href="Chapter_32.html#conclusion"><i class="fa fa-check"></i><b>32.9</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="Chapter_33.html"><a href="Chapter_33.html"><i class="fa fa-check"></i><b>33</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="33.1" data-path="Chapter_33.html"><a href="Chapter_33.html#adjusted-coefficient-of-determination"><i class="fa fa-check"></i><b>33.1</b> Adjusted coefficient of determination</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="Chapter_34.html"><a href="Chapter_34.html"><i class="fa fa-check"></i><b>34</b> <em>Practical</em>. Using regression</a>
<ul>
<li class="chapter" data-level="34.1" data-path="Chapter_34.html"><a href="Chapter_34.html#predicting-pyrogenic-carbon-from-soil-depth"><i class="fa fa-check"></i><b>34.1</b> Predicting pyrogenic carbon from soil depth</a></li>
<li class="chapter" data-level="34.2" data-path="Chapter_34.html"><a href="Chapter_34.html#predicting-pyrogenic-carbon-from-fire-frequency"><i class="fa fa-check"></i><b>34.2</b> Predicting pyrogenic carbon from fire frequency</a></li>
<li class="chapter" data-level="34.3" data-path="Chapter_34.html"><a href="Chapter_34.html#multiple-regression-depth-and-fire-frequency"><i class="fa fa-check"></i><b>34.3</b> Multiple regression depth and fire frequency</a></li>
<li class="chapter" data-level="34.4" data-path="Chapter_34.html"><a href="Chapter_34.html#large-multiple-regression"><i class="fa fa-check"></i><b>34.4</b> Large multiple regression</a></li>
<li class="chapter" data-level="34.5" data-path="Chapter_34.html"><a href="Chapter_34.html#predicting-temperature-from-fire-frequency"><i class="fa fa-check"></i><b>34.5</b> Predicting temperature from fire frequency</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="Chapter_35.html"><a href="Chapter_35.html"><i class="fa fa-check"></i><b>35</b> Randomisation</a>
<ul>
<li class="chapter" data-level="35.1" data-path="Chapter_35.html"><a href="Chapter_35.html#summary-of-parametric-hypothesis-testing"><i class="fa fa-check"></i><b>35.1</b> Summary of parametric hypothesis testing</a></li>
<li class="chapter" data-level="35.2" data-path="Chapter_35.html"><a href="Chapter_35.html#randomisation-approach"><i class="fa fa-check"></i><b>35.2</b> Randomisation approach</a></li>
<li class="chapter" data-level="35.3" data-path="Chapter_35.html"><a href="Chapter_35.html#randomisation-for-hypothesis-testing"><i class="fa fa-check"></i><b>35.3</b> Randomisation for hypothesis testing</a></li>
<li class="chapter" data-level="35.4" data-path="Chapter_35.html"><a href="Chapter_35.html#randomisation-assumptions"><i class="fa fa-check"></i><b>35.4</b> Randomisation assumptions</a></li>
<li class="chapter" data-level="35.5" data-path="Chapter_35.html"><a href="Chapter_35.html#bootstrapping"><i class="fa fa-check"></i><b>35.5</b> Bootstrapping</a></li>
<li class="chapter" data-level="35.6" data-path="Chapter_35.html"><a href="Chapter_35.html#randomisation-conclusions"><i class="fa fa-check"></i><b>35.6</b> Randomisation conclusions</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendexA.html"><a href="appendexA.html"><i class="fa fa-check"></i><b>A</b> Answers to chapter exercises</a>
<ul>
<li class="chapter" data-level="A.1" data-path="appendexA.html"><a href="appendexA.html#chapter-3"><i class="fa fa-check"></i><b>A.1</b> Chapter 3</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="appendexA.html"><a href="appendexA.html#exercise-3.1"><i class="fa fa-check"></i><b>A.1.1</b> Exercise 3.1:</a></li>
<li class="chapter" data-level="A.1.2" data-path="appendexA.html"><a href="appendexA.html#exercise-3.2"><i class="fa fa-check"></i><b>A.1.2</b> Exercise 3.2</a></li>
<li class="chapter" data-level="A.1.3" data-path="appendexA.html"><a href="appendexA.html#exercise-3.2-1"><i class="fa fa-check"></i><b>A.1.3</b> Exercise 3.2</a></li>
<li class="chapter" data-level="A.1.4" data-path="appendexA.html"><a href="appendexA.html#exercise-3.4"><i class="fa fa-check"></i><b>A.1.4</b> Exercise 3.4</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="appendexA.html"><a href="appendexA.html#chapter-8"><i class="fa fa-check"></i><b>A.2</b> Chapter 8</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="appendexA.html"><a href="appendexA.html#exercise-8.1"><i class="fa fa-check"></i><b>A.2.1</b> Exercise 8.1</a></li>
<li class="chapter" data-level="A.2.2" data-path="appendexA.html"><a href="appendexA.html#exercise-8.2"><i class="fa fa-check"></i><b>A.2.2</b> Exercise 8.2</a></li>
<li class="chapter" data-level="A.2.3" data-path="appendexA.html"><a href="appendexA.html#exercise-8.3"><i class="fa fa-check"></i><b>A.2.3</b> Exercise 8.3</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="appendexA.html"><a href="appendexA.html#chapter-14"><i class="fa fa-check"></i><b>A.3</b> Chapter 14</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="appendexA.html"><a href="appendexA.html#exercise-14.1"><i class="fa fa-check"></i><b>A.3.1</b> Exercise 14.1</a></li>
<li class="chapter" data-level="A.3.2" data-path="appendexA.html"><a href="appendexA.html#exercise-14.2"><i class="fa fa-check"></i><b>A.3.2</b> Exercise 14.2</a></li>
<li class="chapter" data-level="A.3.3" data-path="appendexA.html"><a href="appendexA.html#exercise-13.3"><i class="fa fa-check"></i><b>A.3.3</b> Exercise 13.3</a></li>
<li class="chapter" data-level="A.3.4" data-path="appendexA.html"><a href="appendexA.html#exercise-13.4"><i class="fa fa-check"></i><b>A.3.4</b> Exercise 13.4</a></li>
<li class="chapter" data-level="A.3.5" data-path="appendexA.html"><a href="appendexA.html#exercise-13.5"><i class="fa fa-check"></i><b>A.3.5</b> Exercise 13.5</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="appendexA.html"><a href="appendexA.html#chapter-17"><i class="fa fa-check"></i><b>A.4</b> Chapter 17</a>
<ul>
<li class="chapter" data-level="A.4.1" data-path="appendexA.html"><a href="appendexA.html#exercise-17.1"><i class="fa fa-check"></i><b>A.4.1</b> Exercise 17.1</a></li>
<li class="chapter" data-level="A.4.2" data-path="appendexA.html"><a href="appendexA.html#exercise-17.2"><i class="fa fa-check"></i><b>A.4.2</b> Exercise 17.2</a></li>
<li class="chapter" data-level="A.4.3" data-path="appendexA.html"><a href="appendexA.html#exercise-17.3"><i class="fa fa-check"></i><b>A.4.3</b> Exercise 17.3</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="appendexA.html"><a href="appendexA.html#chapter-20"><i class="fa fa-check"></i><b>A.5</b> Chapter 20</a>
<ul>
<li class="chapter" data-level="A.5.1" data-path="appendexA.html"><a href="appendexA.html#exercise-20.1"><i class="fa fa-check"></i><b>A.5.1</b> Exercise 20.1</a></li>
<li class="chapter" data-level="A.5.2" data-path="appendexA.html"><a href="appendexA.html#exercise-20.2"><i class="fa fa-check"></i><b>A.5.2</b> Exercise 20.2</a></li>
<li class="chapter" data-level="A.5.3" data-path="appendexA.html"><a href="appendexA.html#exercise-20.3"><i class="fa fa-check"></i><b>A.5.3</b> Exercise 20.3</a></li>
<li class="chapter" data-level="A.5.4" data-path="appendexA.html"><a href="appendexA.html#exercise-20.4"><i class="fa fa-check"></i><b>A.5.4</b> Exercise 20.4</a></li>
<li class="chapter" data-level="A.5.5" data-path="appendexA.html"><a href="appendexA.html#exercise-20.5"><i class="fa fa-check"></i><b>A.5.5</b> Exercise 20.5</a></li>
</ul></li>
<li class="chapter" data-level="A.6" data-path="appendexA.html"><a href="appendexA.html#chapter-23"><i class="fa fa-check"></i><b>A.6</b> Chapter 23</a>
<ul>
<li class="chapter" data-level="A.6.1" data-path="appendexA.html"><a href="appendexA.html#exercise-23.1"><i class="fa fa-check"></i><b>A.6.1</b> Exercise 23.1</a></li>
<li class="chapter" data-level="A.6.2" data-path="appendexA.html"><a href="appendexA.html#exercise-23.2"><i class="fa fa-check"></i><b>A.6.2</b> Exercise 23.2</a></li>
<li class="chapter" data-level="A.6.3" data-path="appendexA.html"><a href="appendexA.html#exercise-23.3"><i class="fa fa-check"></i><b>A.6.3</b> Exercise 23.3</a></li>
<li class="chapter" data-level="A.6.4" data-path="appendexA.html"><a href="appendexA.html#exercise-23.4"><i class="fa fa-check"></i><b>A.6.4</b> Exercise 23.4</a></li>
<li class="chapter" data-level="A.6.5" data-path="appendexA.html"><a href="appendexA.html#exercise-23.5"><i class="fa fa-check"></i><b>A.6.5</b> Exercise 23.5</a></li>
</ul></li>
<li class="chapter" data-level="A.7" data-path="appendexA.html"><a href="appendexA.html#chapter-28"><i class="fa fa-check"></i><b>A.7</b> Chapter 28</a>
<ul>
<li class="chapter" data-level="A.7.1" data-path="appendexA.html"><a href="appendexA.html#exercise-28.1"><i class="fa fa-check"></i><b>A.7.1</b> Exercise 28.1</a></li>
<li class="chapter" data-level="A.7.2" data-path="appendexA.html"><a href="appendexA.html#exercise-28.2"><i class="fa fa-check"></i><b>A.7.2</b> Exercise 28.2</a></li>
<li class="chapter" data-level="A.7.3" data-path="appendexA.html"><a href="appendexA.html#exercise-28.3"><i class="fa fa-check"></i><b>A.7.3</b> Exercise 28.3</a></li>
<li class="chapter" data-level="A.7.4" data-path="appendexA.html"><a href="appendexA.html#exercise-28.4"><i class="fa fa-check"></i><b>A.7.4</b> Exercise 28.4</a></li>
</ul></li>
<li class="chapter" data-level="A.8" data-path="appendexA.html"><a href="appendexA.html#chapter-31"><i class="fa fa-check"></i><b>A.8</b> Chapter 31</a>
<ul>
<li class="chapter" data-level="A.8.1" data-path="appendexA.html"><a href="appendexA.html#exercise-31.1"><i class="fa fa-check"></i><b>A.8.1</b> Exercise 31.1</a></li>
<li class="chapter" data-level="A.8.2" data-path="appendexA.html"><a href="appendexA.html#exercise-31.2"><i class="fa fa-check"></i><b>A.8.2</b> Exercise 31.2</a></li>
<li class="chapter" data-level="A.8.3" data-path="appendexA.html"><a href="appendexA.html#exercise-31.3"><i class="fa fa-check"></i><b>A.8.3</b> Exercise 31.3</a></li>
<li class="chapter" data-level="A.8.4" data-path="appendexA.html"><a href="appendexA.html#exercise-31.4"><i class="fa fa-check"></i><b>A.8.4</b> Exercise 31.4</a></li>
<li class="chapter" data-level="A.8.5" data-path="appendexA.html"><a href="appendexA.html#exercise-31.5"><i class="fa fa-check"></i><b>A.8.5</b> Exercise 31.5</a></li>
</ul></li>
<li class="chapter" data-level="A.9" data-path="appendexA.html"><a href="appendexA.html#chapter-34"><i class="fa fa-check"></i><b>A.9</b> Chapter 34</a>
<ul>
<li class="chapter" data-level="A.9.1" data-path="appendexA.html"><a href="appendexA.html#exercise-34.1"><i class="fa fa-check"></i><b>A.9.1</b> Exercise 34.1</a></li>
<li class="chapter" data-level="A.9.2" data-path="appendexA.html"><a href="appendexA.html#exercise-34.2"><i class="fa fa-check"></i><b>A.9.2</b> Exercise 34.2</a></li>
<li class="chapter" data-level="A.9.3" data-path="appendexA.html"><a href="appendexA.html#exercise-34.3"><i class="fa fa-check"></i><b>A.9.3</b> Exercise 34.3</a></li>
<li class="chapter" data-level="A.9.4" data-path="appendexA.html"><a href="appendexA.html#exercise-34.4"><i class="fa fa-check"></i><b>A.9.4</b> Exercise 34.4</a></li>
<li class="chapter" data-level="A.9.5" data-path="appendexA.html"><a href="appendexA.html#exercise-33.5"><i class="fa fa-check"></i><b>A.9.5</b> Exercise 33.5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="uncertainty_derivation.html"><a href="uncertainty_derivation.html"><i class="fa fa-check"></i><b>B</b> Uncertainty derivation</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamental statistical concepts and techniques in the biological and environmental sciences: With jamovi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Chapter_12" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Chapter 12</span> Measures of spread<a href="Chapter_12.html#Chapter_12" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>It is often important to know how much a set of numbers is spread out.
That is, do all of the data cluster close to the mean, or are most values distant from the mean.
For example, all of the numbers below are quite close to the mean of 5.0 (3 numbers are exactly 5.0).</p>
<pre><code>4.9, 5.3, 5.0, 4.7, 5.1, 5.0, 5.0</code></pre>
<p>In contrast, all of the numbers that follow are relatively distant from the same mean of 5.0.</p>
<pre><code>3.0, 5.6, 7.8, 1.2, 4.3, 8.2, 4.9</code></pre>
<p>This chapter focuses on summary statistics that describe the spread of data.
The approach in this chapter is similar to <a href="Chapter_11.html#Chapter_11">Chapter 11</a>, which provided verbal and mathematical explanations of measures of central tendency.
We will start with the most intuitive measures of spread, the range and inter-quartile range.
Then, we will move on to some more conceptually challenging measures of spread, the variance, standard deviation, coefficient of variation, and standard error.
These more challenging measures can be a bit confusing at first, but they are absolutely critical for doing statistics.
The best approach to learning them is to see them and practice using them in different contexts, which we will do throughout this book.</p>
<div id="the-range" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> The range<a href="Chapter_12.html#the-range" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The range of a set of numbers is probably the most intuitive measure of spread.
It is simply the difference between the highest and the lowest value of a dataset <span class="citation">(<a href="#ref-Sokal1995" role="doc-biblioref">Sokal and Rohlf 1995</a>)</span>.
To calculate it, we just need to take the highest value minus the lowest value.
If we want to be fancy, then we can write a general equation for the range of a random variable <span class="math inline">\(X\)</span>,</p>
<p><span class="math display">\[Range(X) = \max(X) - \min(X).\]</span></p>
<p>But really, all that we need to worry about is finding the highest and lowest values, then subtracting.
Consider again the two sets of numbers introduced at the beginning of the chapter.
In examples, it is often helpful to imagine numbers as representing something concrete that has been measured, so suppose that these numbers are the measured masses (in grams) of leaves from two different plants.
Below are the masses of plant A, in which leaf masses are very similar and close to the mean of 5.</p>
<pre><code>4.9, 5.3, 5.0, 4.7, 5.1, 5.0, 5.0</code></pre>
<p>Plant B masses are below, which are more spread out around the same mean of 5.</p>
<pre><code>3.0, 5.6, 7.8, 1.2, 4.3, 8.2, 4.9</code></pre>
<p>To get the range of plant A, we just need to find the highest (5.3 g) and lowest (4.7 g) mass, then subtract,</p>
<p><span class="math display">\[Range(Plant\:A) = 5.3 - 4.7 = 0.6\]</span></p>
<p>Plant A therefore has a range of 0.6 g.
We can do the same for plant B, which has a highest value of 8.2 g and lowest value of 1.2 g,</p>
<p><span class="math display">\[Range(Plant\:B) = 8.2 - 1.2 = 7.0\]</span></p>
<p>Plant B therefore has a much higher range than plant A.</p>
<p>It is important to mention that the range is highly sensitive to outliers <span class="citation">(<a href="#ref-Navarro2022" role="doc-biblioref">Navarro and Foxcroft 2022</a>)</span>.
Just adding a single number to either plant A or plant B could dramatically change the range.
For example, imagine if we measured a leaf in plant A to have a mass of 19.7 g (i.e., we found a huge leaf!).
The range of plant A would then be <span class="math inline">\(19.7 - 4.7 = 14\)</span> instead of 0.6!
Just this one massive leaf would then make the range of plant A double the range of plant B.
This lack of robustness can really limit how useful the range is as a statistical measure of spread.</p>
</div>
<div id="the-inter-quartile-range" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> The inter-quartile range<a href="Chapter_12.html#the-inter-quartile-range" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The inter-quartile range (usually abbreviated as ‘IQR’) is conceptually the same as the range.
The only difference is that we are calculating the range between quartiles rather than the range between the highest and lowest numbers in the dataset.
A general formula subtracting the first quartile (<span class="math inline">\(Q_{1}\)</span>) from the third quartile (<span class="math inline">\(Q_{3}\)</span>) is,</p>
<p><span class="math display">\[IQR = Q_{3} - Q_{1}.\]</span></p>
<p>Recall from <a href="Chapter_11.html#Chapter_11">Chapter 11</a> how to calculate first and third quartiles.
As a reminder, we can sort the leaf masses for plant A below.</p>
<pre><code>4.7, 4.9, 5.0, 5.0, 5.0, 5.1, 5.3</code></pre>
<p>The first quartile will be the mean between 4.9 and 5.0 (4.95).
The third quartile will be the the mean between 5.0 and 5.1 (5.05).
The IQR of plant A is therefore,</p>
<p><span class="math display">\[IQR_{plant\:A} = 5.05 - 4.95 = 0.1.\]</span></p>
<p>We can calculate the IQR for plant B in the same way.
Here are the masses of plant B leaves sorted.</p>
<pre><code>1.2, 3.0, 4.3, 4.9, 5.6, 7.8, 8.2</code></pre>
<p>The first quartile of plant B is 3.65, and the third quartile is 6.70.
To get the IQR of plant B,</p>
<p><span class="math display">\[IQR_{plant\:B} = 6.70 - 3.65 = 3.05.\]</span></p>
<p>An important point about the IQR is that it is more robust than the range <span class="citation">(<a href="#ref-Dytham2011" role="doc-biblioref">Dytham 2011</a>)</span>.
Recall that if we found an outlier leaf of 19.7 g on plant A, it would change the range of plant leaf mass from 0.6 g to 14 g.
The IQR is not nearly so sensitive.
If we include the outlier, the first quartile for plant A changes from <span class="math inline">\(Q_{1} = 4.95\)</span> to <span class="math inline">\(Q_{1} = 4.975\)</span>.
The third quartile changes from <span class="math inline">\(Q_{3} = 5.05\)</span> to <span class="math inline">\(Q_{3} = 5.150\)</span>.
The resulting IQR is therefore <span class="math inline">\(5.150 - 4.975 = 0.175\)</span>.
Hence, the IQR only changes from 0.1 to 0.175, rather than from 0.6 to 14.
The one outlier therefore has a huge effect on the range, but only a modest effect on the IQR.</p>
</div>
<div id="the-variance" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> The variance<a href="Chapter_12.html#the-variance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The range and inter-quartile range were reasonably intuitive, in the sense that it is not too difficult to think about what a range of 10, e.g., actually means in terms of the data.
We now move to measures of spread that are less intuitive.
These measures of spread are the variance, standard deviation, coefficient of variation, and standard error.
These can be confusing and unintuitive at first, but they are extremely useful.
We will start with the variance; this section is long because we want to break the variance down carefully, step by step.</p>
<p>The sample variance of a dataset is a measure of the expected squared distance of data from the mean.
To calculate the variance of a sample, we need to know the sample size (<span class="math inline">\(N\)</span>, i.e., how many measurements in total), and the mean of the sample (<span class="math inline">\(\bar{x}\)</span>).
We can calculate the variance of a sample (<span class="math inline">\(s^{2}\)</span>) as follows,</p>
<p><span class="math display">\[s^{2} = \frac{1}{N - 1}\sum_{i = 1}^{N}\left(x_{i} - \bar{x} \right)^{2}.\]</span></p>
<p>This looks like a lot, but we can break down what the equation is doing verbally.
First, we can look inside the summation (<span class="math inline">\(\sum\)</span>).
Here we are taking an individual measurement <span class="math inline">\(x_{i}\)</span>, subtracting the mean <span class="math inline">\(\bar{x}\)</span>, then squaring.
We do this for each <span class="math inline">\(x_{i}\)</span>, summing up all of the values from <span class="math inline">\(i = 1\)</span> to <span class="math inline">\(i = N\)</span>.
This part of the equation is called the <strong>sum of squares</strong> (<span class="math inline">\(SS\)</span>),</p>
<p><span class="math display">\[SS = \sum_{i = 1}^{N}\left(x_{i} - \bar{x} \right)^{2}.\]</span></p>
<p>That is, we need to subtract the mean from each value <span class="math inline">\(x_{i}\)</span>, square the result, and add everything up.
Once we have this sum, <span class="math inline">\(SS\)</span>, then we just need to multiply by <span class="math inline">\(1 / (N - 1)\)</span> to get the variance.</p>
<p>An example of how to do the actual calculation should help make it easier to understand what is going on.
We can use the same values from plant A earlier.</p>
<pre><code>4.9, 5.3, 5.0, 4.7, 5.1, 5.0, 5.0</code></pre>
<p>To calculate the variance of plant A leaf masses, we start with the sum of squares.
That is, take 4.9, subtract the sample mean of 5.0 (<span class="math inline">\(4.9 - 5.0 = -0.1\)</span>), then square the result (<span class="math inline">\((-0.1)^{2} = 0.01\)</span>).
We do the same for 5.3, <span class="math inline">\((5.3 - 5.0)^{2} = 0.09\)</span>, and add it to the 0.01, then continue down the list of numbers finishing with 5.0.
This is what the sum of squares calculation looks like all written out,</p>
<p><span class="math display">\[SS = (4.9 - 5)^{2} + (5.3 - 5)^{2} + (5 - 5)^{2} + (4.7 - 5)^{2} + (5.1 - 5)^{2} + (5 - 5)^{2} + (5 - 5)^{2}.\]</span></p>
<p>Remember that the calculations in parentheses need to be done first, so the next step for calculating the sum of squares would be the following,</p>
<p><span class="math display">\[SS = (-0.1)^{2} + (0.3)^{2} + (0)^{2} + (-0.3)^{2} + (0.1)^{2} + (0)^{2} + (0)^{2}.\]</span></p>
<p>Next, we need to square all of the values,</p>
<p><span class="math display">\[SS = 0.01 + 0.09 + 0 + 0.09 + 0.01 + 0 + 0.\]</span></p>
<p>If we sum the above, we get <span class="math inline">\(SS = 0.2\)</span>.
We now just need to multiply this by <span class="math inline">\(1 / (N - 1)\)</span>, where <span class="math inline">\(N = 7\)</span> because this is the total number of measurements in the plant A dataset,</p>
<p><span class="math display">\[s^{2} = \frac{1}{7 - 1}\left(0.2\right).\]</span></p>
<p>From the above, we get a variance of approximately <span class="math inline">\(s^{2} = 0.0333\)</span>.</p>
<p>Fortunately, it will almost never be necessary to calculate a variance manually in this way.
Jamovi will do all of these steps and calculate the variance for us (<a href="Chapter_14.html#Chapter_14">Chapter 14</a> explains how).
The only reason that we present the step-by-step calculation here is to help explain the equation for <span class="math inline">\(s^{2}\)</span>.
The details can be helpful for understanding how the variance works as a measure of spread.
For example, note that what we are really doing here is getting the distance of each value from the mean, <span class="math inline">\(x_{i} - \bar{x}\)</span>.
If these distances tend to be large, then it means that most data points (<span class="math inline">\(x_{i}\)</span>) are far away from the mean (<span class="math inline">\(\bar{x}\)</span>), and the variance (<span class="math inline">\(s^{2}\)</span>) will therefore increase.
The differences <span class="math inline">\(x_{i} - \bar{x}\)</span> are squared because we need all of the values to be positive, so that variance increases regardless of whether a value <span class="math inline">\(x_{i}\)</span> is higher or lower than the mean.
It does not matter if <span class="math inline">\(x_{i}\)</span> is 0.1 lower than <span class="math inline">\(\bar{x}\)</span> (i.e., <span class="math inline">\(x_{i} - \bar{x} = -0.1\)</span>), or 0.1 higher (i.e., <span class="math inline">\(x_{i} - \bar{x} = 0.1\)</span>).
In both cases, the deviation from the mean is the same.
Moreover, if we did not square the values, then the sum of <span class="math inline">\(x_{i} - \bar{x}\)</span> values would always be 0 (you can try this yourself)<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>.
Lastly, it turns out that the variance is actually a special case of a more general concept called the <em>covariance</em>, which we will look at later in <a href="Chapter_30.html#Chapter_30">Chapter 30</a> and makes the squaring of differences make a bit more sense.</p>
<p>We sum up all of the squared deviations to get the <span class="math inline">\(SS\)</span>, then divide by the sample size minus 1, to get the mean squared deviation from the mean.
That is, the whole process gives us the <em>average</em> squared deviation from the mean.
But wait, why is it the sample size minus 1, <span class="math inline">\(N - 1\)</span>?
Why would we subtract 1 here?
The short answer is that in calculating a <em>sample</em> variance, <span class="math inline">\(s^{2}\)</span>, we are almost always trying to estimate the corresponding <em>population</em> variance (<span class="math inline">\(\sigma^{2}\)</span>).
And if we were to just use <span class="math inline">\(N\)</span> instead of <span class="math inline">\(N - 1\)</span>, then our <span class="math inline">\(s^{2}\)</span> would be a biased estimate of <span class="math inline">\(\sigma^{2}\)</span> (see <a href="Chapter_4.html#Chapter_4">Chapter 4</a> for a reminder on the difference between samples and populations).
By subtracting 1, we are correcting for this bias to get a more accurate estimate of the population variance<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>.
It is not necessary to do this ourselves; jamovi will do it automatically <span class="citation">(<a href="#ref-Jamovi2022" role="doc-biblioref">The Jamovi Project 2022</a>)</span>.
The subtraction is required due to a reduction in the <em>degrees of freedom</em> that occurs when using the sample mean in the equation for variance<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>.</p>
<p><strong>Degrees of freedom</strong> is a difficult concept to understand, but we can broadly define the degree of freedom as the number of independent pieces of information that we have when calculating a statistic <span class="citation">(<a href="#ref-Grafen2002" role="doc-biblioref">Grafen and Hails 2022</a>; <a href="#ref-Upton2014" role="doc-biblioref">Upton and Cook 2014</a>)</span>.
When we need to estimate a parameter from a dataset in the process of calculating a statistic, we lose an independent piece of information, and therefore a degree of freedom <span class="citation">(<a href="#ref-Pandey2008" role="doc-biblioref">Pandey and Bright 2008</a>)</span>.
For example, if we collect <span class="math inline">\(N = 10\)</span> samples, then there are 10 independent pieces of information that we can use to calculate the mean.
To calculate the variance, we use all of these 10 samples <em>and</em> <span class="math inline">\(\bar{x}\)</span> (note that <span class="math inline">\(\bar{x}\)</span> appears in the equation for variance above).
This suggests that we actually have 11 independent pieces of information in making our calculation (all of the samples and the sample mean).
But not all of these values are actually free to vary.
When we know what the 10 sample values are, then the sample mean is fixed.
And if we know what 9 sample values are and what the mean is, then we can work what the last sample value must be.
We therefore lose a degree of freedom by including <span class="math inline">\(\bar{x}\)</span> in the calculation of variance, so we need to divide by <span class="math inline">\(N - 1\)</span> rather than <span class="math inline">\(N\)</span> to avoid bias <span class="citation">(<a href="#ref-Wardlaw1985" role="doc-biblioref">Wardlaw 1985</a>; <a href="#ref-Fowler1998" role="doc-biblioref">Fowler, Cohen, and Jarvis 1998</a>)</span>.
Another way of thinking about degrees of freedom is as the number of differences that can arise between what we sample versus what we expect just based on the mathematics <span class="citation">(<a href="#ref-Fryer1966" role="doc-biblioref">Fryer 1966</a>)</span>.
In other words, how much is our calculation free to vary just due to chance?
In calculating the variance, the mathematics introduces a constraint by including <span class="math inline">\(\bar{x}\)</span>, thereby reducing degrees of freedom.</p>
<p>This was a lot of information.
The variance is not an intuitive concept.
In addition to being a challenge to calculate, the calculation of a variance leaves us with a value in units squared.
That is, for the example of plant leaf mass in grams, the variance is measured in grams squared, <span class="math inline">\(g^{2}\)</span>, which is not particularly easy to interpret.
For more on this, <span class="citation">Navarro and Foxcroft (<a href="#ref-Navarro2022" role="doc-biblioref">2022</a>)</span> have a really good <a href="https://davidfoxcroft.github.io/lsj-book/04-Descriptive-statistics.html#variance">section</a> on the variance.
Despite its challenges as a descriptive statistic, the variance has some mathematical properties that are very useful <span class="citation">(<a href="#ref-Navarro2022" role="doc-biblioref">Navarro and Foxcroft 2022</a>)</span>, especially in the biological and environmental sciences.</p>
<p>For example, variances are additive, meaning that if we are measuring two separate characteristics of a sample, A and B, then the variance of A+B equals the variance of A plus the variance of B; i.e., <span class="math inline">\(Var(A + B) = Var(A) + Var(B)\)</span> <a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>.
This is relevant to genetics when measuring heritability.
Here, the total variance in the phenotype of a population (e.g., body mass of animals) can be partitioned into variance attributable to genetics plus variance attributable to the environment,</p>
<p><span class="math display">\[Var(Phenotype) = Var(Genotype) + Var(Environment).\]</span></p>
<p>This is also sometimes written as <span class="math inline">\(V_{P} = V_{G} + V_{E}\)</span>.
Applying this equation to calculate heritability (<span class="math inline">\(H^{2} = V_{G} / V_{P}\)</span>) can be used to predict how a population will respond to natural selection.
This is just one place where variance reveals itself to be a highly useful statistic in practice.
Nevertheless, as a descriptive statistic to communicate the spread of a variable, it usually makes more sense to calculate the standard deviation of the mean.</p>
</div>
<div id="the-standard-deviation" class="section level2 hasAnchor" number="12.4">
<h2><span class="header-section-number">12.4</span> The standard deviation<a href="Chapter_12.html#the-standard-deviation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The standard deviation of the mean (<span class="math inline">\(s\)</span>) is just the square root of the variance,</p>
<p><span class="math display">\[s = \sqrt{\frac{1}{N - 1}\sum_{i = 1}^{N}\left(x_{i} - \bar{x} \right)^{2}}.\]</span></p>
<p>This is a simple step, mathematically, but it also is easier to understand conceptually as a measure of spread <span class="citation">(<a href="#ref-Navarro2022" role="doc-biblioref">Navarro and Foxcroft 2022</a>)</span>.
By taking the square root of the variance, our units are no longer squared, so we can interpret the standard deviation in the same terms as our original data.
For example, the leaf masses of plant A and plant B in the example above were measured in grams.
While the variance of these masses were in <span class="math inline">\(g^{2}\)</span>, the standard deviation is in <span class="math inline">\(g\)</span>, just like the original measurements.
For plant A, we calculated a leaf mass variance of <span class="math inline">\(s^{2} = 0.0333\:g^{2}\)</span>, which means that the standard deviation of leaf masses is <span class="math inline">\(s = \sqrt{0.0333\:g^{2}} = 0.1825\:g\)</span>.
Because we are reporting <span class="math inline">\(s\)</span> in the original units, it is a very useful measure of spread to report, and it is an important one to be able to interpret.
To help with the interpretation, an interactive tool can more effectively show how the heights of trees in a forest change across different standard deviation values<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a>.
Another interactive tool can help show how the shape of a histogram changes when the standard deviation of a distribution is changed<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a>.
<a href="Chapter_14.html#Chapter_14">Chapter 14</a> explains how to calculate the standard deviation in jamovi.</p>
</div>
<div id="the-coefficient-of-variation" class="section level2 hasAnchor" number="12.5">
<h2><span class="header-section-number">12.5</span> The coefficient of variation<a href="Chapter_12.html#the-coefficient-of-variation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The coefficient of variation (CV) is just the standard deviation divided by the mean,</p>
<p><span class="math display">\[CV = \frac{s}{\bar{x}}.\]</span></p>
<p>Dividing by the mean seems a bit arbitrary at first, but this can often be useful for comparing variables with different means or different units.
The reason for this is that the units cancel out when dividing the standard deviation by the mean.
For example, for the leaf masses of plant A, we calculated a standard deviation of 0.1825 g and a mean of 5 g.
We can see the units cancel below,</p>
<p><span class="math display">\[CV = \frac{0.1825\:g}{5\:g} = 0.0365.\]</span></p>
<p>The resulting CV of 0.0365 has no units; it is <em>dimensionless</em> <span class="citation">(<a href="#ref-Lande1977" role="doc-biblioref">Lande 1977</a>)</span>.
Because it has no units, it often used to compare measurements with much different means or with different measurement units.
For example, <span class="citation">Sokal and Rohlf (<a href="#ref-Sokal1995" role="doc-biblioref">1995</a>)</span> suggest that biologists might want to compare tail length variation between animals with much different body sizes, such as elephants and mice.
The standard deviation of tail lengths between these two species will likely be much different just because of their difference in size, so by standardising by mean tail length, it can be easier to compare relative standard deviation.
This is a common application of the CV in biology, but it needs to be interpreted carefully <span class="citation">(<a href="#ref-Pelabon2020" role="doc-biblioref">Pélabon et al. 2020</a>)</span>.</p>
<p>Often, we will want to express the coefficient of variation as a percentage of the mean.
To do this, we just need to multiply the CV above by 100%.
For example, to express the CV as a percentage, we would multiply the 0.0365 above by 100%, which would give us a final answer of <span class="math inline">\(CV = 3.65\)</span>%.</p>
</div>
<div id="the-standard-error" class="section level2 hasAnchor" number="12.6">
<h2><span class="header-section-number">12.6</span> The standard error<a href="Chapter_12.html#the-standard-error" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The standard error of the mean is the last measurement that we will introduce here.
It is slightly different than the previous estimates in that it is a measure of the variation in the <em>mean</em> of a sample rather than the sample itself.
That is, the standard error tells us how far our sample mean <span class="math inline">\(\bar{x}\)</span> is expected to deviate from the true mean <span class="math inline">\(\mu\)</span>.
Technically, the standard error of the mean is the standard deviation <em>of sample means</em> rather than the standard deviation <em>of samples</em>.
What does that even mean?
It is easier to explain with a concrete example.</p>
<p>Imagine that we want to measure nitrogen levels in the water of Airthrey Loch (note that ‘loch’ is the Scottish word for ‘lake’).
We collect 12 water samples and record the nitrate levels in milligrams per litre (mg/l).
The measurements are reported below.</p>
<pre><code>0.63, 0.60, 0.53, 0.72, 0.61, 0.48, 0.67, 0.59, 0.67, 0.54, 0.47, 0.87</code></pre>
<p>We can calculate the mean of the above sample to be <span class="math inline">\(\bar{x} = 0.615\)</span>, and we can calculate the standard deviation of the sample to be <span class="math inline">\(s = 0.111\)</span>.
We do not know what the <em>true</em> mean <span class="math inline">\(\mu\)</span> is, but our best guess is the sample mean <span class="math inline">\(\bar{x}\)</span>.
Suppose, however, that we then went back to the loch to collect another 12 measurements (assume that the nitrogen level of the lake has not changed in the meantime).
We would expect to get values similar to our first 12 measurements, but certainly not the <em>exact</em> same measurements, right?
The sample mean of these new measurements would also be a bit different.
Maybe we actually go out and do this and get the following new sample.</p>
<pre><code>0.47, 0.56, 0.72, 0.61, 0.54, 0.64, 0.68, 0.54, 0.48, 0.59, 0.62, 0.78</code></pre>
<p>The mean of our new sample is 0.603, which is a bit different from our first.
In other words, the sample means vary.
We can therefore ask what is the variance and standard deviation <em>of the sample means</em>.
In other words, suppose that we kept going back out to the loch, collecting 12 new samples, and recording the sample mean each time?
The standard deviation of those sample means would be the standard error.
<strong>The standard error is the standard deviation of <span class="math inline">\(\bar{x}\)</span> values around the true mean <span class="math inline">\(\mu\)</span>.</strong>
But we do not actually need to go through the repetitive resampling process to estimate the standard error.
We can estimate it with just the standard deviation and the sample size.
To do this, we just need to take the standard deviation of the sample (<span class="math inline">\(s\)</span>) and divide by the square root of the sample size (<span class="math inline">\(\sqrt{N}\)</span>),</p>
<p><span class="math display">\[SE = \frac{s}{\sqrt{N}}.\]</span></p>
<p>In the case of the first 12 samples from the loch in the example above,</p>
<p><span class="math display">\[SE = \frac{0.111}{\sqrt{12}} = 0.032.\]</span></p>
<p>The standard error is important because it can be used to evaluate the uncertainty of the sample mean in comparison with the true mean.
We can use the standard error to place confidence intervals around our sample mean to express this uncertainty.
We will calculate confidence intervals in <a href="Chapter_18.html#Chapter_18">Chapter 18</a>, so it is important to understand what the standard error is measuring.</p>
<p>If the concept of standard error is still a bit unclear, we can work through one more hypothetical example.
Suppose again that we want to measure the nitrogen concentration of a loch.
This time, however, assume that we somehow <em>know</em> that the true mean N concentration is <span class="math inline">\(\mu = 0.7\)</span>, and that the standard deviation of water sample N concentration is <span class="math inline">\(\sigma = 0.1\)</span>.
Of course, we can never actually know the <em>true</em> parameter values, but we can use a computer to simulate sampling from a population in which the true parameter values are known.
In Table 12.1, we simulate the process of going out and collecting 10 water samples from Airthrey Loch.
This collecting of 10 water samples is repeated 20 different times.
Each row is a different sampling effort, and columns report the 10 samples from each effort.</p>
<table>
<caption><strong>TABLE 12.1</strong> Simulated samples of nitrogen content from water samples of Airthrey Loch. Values are sampled from a normal distribution with a mean of 0.7 and a standard deviation 0.1.</caption>
<colgroup>
<col width="18%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center"><strong>Sample_1</strong></td>
<td align="center">0.84</td>
<td align="center">0.84</td>
<td align="center">0.71</td>
<td align="center">0.7</td>
<td align="center">0.68</td>
<td align="center">0.82</td>
<td align="center">0.74</td>
<td align="center">0.82</td>
<td align="center">0.57</td>
<td align="center">0.81</td>
</tr>
<tr class="even">
<td align="center"><strong>Sample_2</strong></td>
<td align="center">0.74</td>
<td align="center">0.82</td>
<td align="center">0.77</td>
<td align="center">0.82</td>
<td align="center">0.85</td>
<td align="center">0.73</td>
<td align="center">0.62</td>
<td align="center">0.77</td>
<td align="center">0.49</td>
<td align="center">0.66</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sample_3</strong></td>
<td align="center">0.62</td>
<td align="center">0.74</td>
<td align="center">0.69</td>
<td align="center">0.86</td>
<td align="center">0.69</td>
<td align="center">0.63</td>
<td align="center">0.62</td>
<td align="center">0.79</td>
<td align="center">0.76</td>
<td align="center">0.52</td>
</tr>
<tr class="even">
<td align="center"><strong>Sample_4</strong></td>
<td align="center">0.63</td>
<td align="center">0.57</td>
<td align="center">0.73</td>
<td align="center">0.77</td>
<td align="center">0.72</td>
<td align="center">0.62</td>
<td align="center">0.81</td>
<td align="center">0.51</td>
<td align="center">0.89</td>
<td align="center">0.75</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sample_5</strong></td>
<td align="center">0.75</td>
<td align="center">0.8</td>
<td align="center">0.66</td>
<td align="center">0.7</td>
<td align="center">0.73</td>
<td align="center">0.61</td>
<td align="center">0.53</td>
<td align="center">0.71</td>
<td align="center">0.66</td>
<td align="center">0.71</td>
</tr>
<tr class="even">
<td align="center"><strong>Sample_6</strong></td>
<td align="center">0.79</td>
<td align="center">0.56</td>
<td align="center">0.81</td>
<td align="center">0.87</td>
<td align="center">0.61</td>
<td align="center">0.59</td>
<td align="center">0.75</td>
<td align="center">0.71</td>
<td align="center">0.6</td>
<td align="center">0.68</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sample_7</strong></td>
<td align="center">0.81</td>
<td align="center">0.79</td>
<td align="center">0.92</td>
<td align="center">0.68</td>
<td align="center">0.92</td>
<td align="center">0.58</td>
<td align="center">0.83</td>
<td align="center">0.7</td>
<td align="center">0.79</td>
<td align="center">0.66</td>
</tr>
<tr class="even">
<td align="center"><strong>Sample_8</strong></td>
<td align="center">0.65</td>
<td align="center">0.68</td>
<td align="center">0.67</td>
<td align="center">0.78</td>
<td align="center">0.66</td>
<td align="center">0.77</td>
<td align="center">0.69</td>
<td align="center">0.8</td>
<td align="center">0.71</td>
<td align="center">0.83</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sample_9</strong></td>
<td align="center">0.64</td>
<td align="center">0.66</td>
<td align="center">0.84</td>
<td align="center">0.77</td>
<td align="center">0.61</td>
<td align="center">0.8</td>
<td align="center">0.87</td>
<td align="center">0.72</td>
<td align="center">0.7</td>
<td align="center">0.77</td>
</tr>
<tr class="even">
<td align="center"><strong>Sample_10</strong></td>
<td align="center">0.68</td>
<td align="center">0.78</td>
<td align="center">0.61</td>
<td align="center">0.66</td>
<td align="center">0.8</td>
<td align="center">0.6</td>
<td align="center">0.85</td>
<td align="center">0.59</td>
<td align="center">0.55</td>
<td align="center">0.54</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sample_11</strong></td>
<td align="center">0.83</td>
<td align="center">0.85</td>
<td align="center">0.94</td>
<td align="center">0.73</td>
<td align="center">0.65</td>
<td align="center">0.58</td>
<td align="center">0.8</td>
<td align="center">0.68</td>
<td align="center">0.82</td>
<td align="center">0.54</td>
</tr>
<tr class="even">
<td align="center"><strong>Sample_12</strong></td>
<td align="center">0.88</td>
<td align="center">0.63</td>
<td align="center">0.7</td>
<td align="center">0.72</td>
<td align="center">0.72</td>
<td align="center">0.69</td>
<td align="center">0.63</td>
<td align="center">0.53</td>
<td align="center">0.68</td>
<td align="center">0.72</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sample_13</strong></td>
<td align="center">0.72</td>
<td align="center">0.69</td>
<td align="center">0.69</td>
<td align="center">0.7</td>
<td align="center">0.69</td>
<td align="center">0.68</td>
<td align="center">0.56</td>
<td align="center">0.64</td>
<td align="center">0.73</td>
<td align="center">0.77</td>
</tr>
<tr class="even">
<td align="center"><strong>Sample_14</strong></td>
<td align="center">0.69</td>
<td align="center">0.5</td>
<td align="center">0.64</td>
<td align="center">0.76</td>
<td align="center">0.73</td>
<td align="center">0.7</td>
<td align="center">0.94</td>
<td align="center">0.7</td>
<td align="center">0.61</td>
<td align="center">0.65</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sample_15</strong></td>
<td align="center">0.77</td>
<td align="center">0.81</td>
<td align="center">0.72</td>
<td align="center">0.62</td>
<td align="center">0.72</td>
<td align="center">0.76</td>
<td align="center">0.58</td>
<td align="center">0.77</td>
<td align="center">0.75</td>
<td align="center">0.54</td>
</tr>
<tr class="even">
<td align="center"><strong>Sample_16</strong></td>
<td align="center">0.65</td>
<td align="center">0.58</td>
<td align="center">0.6</td>
<td align="center">0.61</td>
<td align="center">0.78</td>
<td align="center">0.47</td>
<td align="center">0.73</td>
<td align="center">0.63</td>
<td align="center">0.62</td>
<td align="center">0.95</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sample_17</strong></td>
<td align="center">0.7</td>
<td align="center">0.69</td>
<td align="center">0.65</td>
<td align="center">0.72</td>
<td align="center">0.65</td>
<td align="center">0.79</td>
<td align="center">0.54</td>
<td align="center">0.77</td>
<td align="center">1</td>
<td align="center">0.69</td>
</tr>
<tr class="even">
<td align="center"><strong>Sample_18</strong></td>
<td align="center">0.73</td>
<td align="center">0.5</td>
<td align="center">0.71</td>
<td align="center">0.75</td>
<td align="center">0.75</td>
<td align="center">0.71</td>
<td align="center">0.83</td>
<td align="center">0.64</td>
<td align="center">0.71</td>
<td align="center">0.61</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sample_19</strong></td>
<td align="center">0.61</td>
<td align="center">0.78</td>
<td align="center">0.62</td>
<td align="center">0.66</td>
<td align="center">0.66</td>
<td align="center">0.65</td>
<td align="center">0.56</td>
<td align="center">0.64</td>
<td align="center">0.99</td>
<td align="center">0.65</td>
</tr>
<tr class="even">
<td align="center"><strong>Sample_20</strong></td>
<td align="center">0.75</td>
<td align="center">0.58</td>
<td align="center">0.67</td>
<td align="center">0.79</td>
<td align="center">0.78</td>
<td align="center">0.64</td>
<td align="center">0.74</td>
<td align="center">0.56</td>
<td align="center">0.63</td>
<td align="center">0.67</td>
</tr>
</tbody>
</table>
<p>We can calculate the mean of each sample by calculating the mean of each row.
These 20 means are reported below.</p>
<pre><code>      [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
[1,] 0.753 0.727 0.692 0.700 0.686 0.697 0.768 0.724 0.738 0.666
[2,] 0.742 0.690 0.687 0.692 0.704 0.662 0.720 0.694 0.682 0.681</code></pre>
<p>The standard deviation of the 20 sample means reported above is 0.0287766.
Now suppose that we only had Sample 1 (i.e., the top row of data).
The standard deviation of Sample 1 is <span class="math inline">\(s =\)</span> 0.0888257.
We can calculate the standard error from these sample values below,</p>
<p><span class="math display">\[s = \frac{0.0888257}{\sqrt{10}} = 0.0280891.\]</span></p>
<p>The estimate of the standard error from calculating the standard deviation of the sample means is therefore 0.0287766, and the estimate from just using the standard error formula and data from only Sample 1 is 0.0280891.
These are reasonably close, and would be even closer if we had either a larger sample size in each sample (i.e., higher <span class="math inline">\(N\)</span>) or a larger number of samples.</p>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Dytham2011" class="csl-entry">
Dytham, Calvin. 2011. <em><span class="nocase">Choosing and Using Statistics: A Biologist’s Guide</span></em>. John Wiley &amp; Sons.
</div>
<div id="ref-Fowler1998" class="csl-entry">
Fowler, Jim, Lou Cohen, and Phil Jarvis. 1998. <em><span class="nocase">Practical Statistics for Field Biology</span></em>. 2nd ed. Chichester, UK: John Wiley &amp; Sons.
</div>
<div id="ref-Fryer1966" class="csl-entry">
Fryer, Holly C. 1966. <em><span class="nocase">Concepts and Methods of Experimental Statistics</span></em>. Boston: Allyn; Bacon.
</div>
<div id="ref-Grafen2002" class="csl-entry">
Grafen, Alan, and Rosie Hails. 2022. <em><span class="nocase">Modern Statistics for the Life Sciences</span></em>. Oxford: Oxford University Press.
</div>
<div id="ref-Lande1977" class="csl-entry">
Lande, Russell. 1977. <span>“<span class="nocase">On comparing coefficients of variation.</span>”</span> <em>Systematic Zoology</em> 26 (2): 214–17.
</div>
<div id="ref-Navarro2022" class="csl-entry">
Navarro, Danielle J, and David R Foxcroft. 2022. <em><span class="nocase">Learning Statistics with Jamovi</span></em>. (Version 0.75). <a href="https://doi.org/10.24384/hgc3-7p15">https://doi.org/10.24384/hgc3-7p15</a>.
</div>
<div id="ref-Pandey2008" class="csl-entry">
Pandey, Shanta, and Charlotte Lyn Bright. 2008. <span>“<span class="nocase">What are degrees of freedom?</span>”</span> <em>Social Work Research</em> 32 (2): 119–28. <a href="https://doi.org/10.1080/00031305.1974.10479077">https://doi.org/10.1080/00031305.1974.10479077</a>.
</div>
<div id="ref-Pelabon2020" class="csl-entry">
Pélabon, Christophe, Christoffer H Hilde, Sigurd Einum, and Marlène Gamelon. 2020. <span>“<span class="nocase">On the use of the coefficient of variation to quantify and compare trait variation</span>.”</span> <em>Evolution Letters</em> 4 (3): 180–88. <a href="https://doi.org/10.1002/evl3.171">https://doi.org/10.1002/evl3.171</a>.
</div>
<div id="ref-Sokal1995" class="csl-entry">
Sokal, Robert R, and F James Rohlf. 1995. <em><span>Biometry</span></em>. 3rd ed. New York: W. H. Freeman; Company.
</div>
<div id="ref-Jamovi2022" class="csl-entry">
The Jamovi Project. 2022. <span>“Jamovi.”</span> Sydney, Australia. <a href="https://www.jamovi.org">https://www.jamovi.org</a>.
</div>
<div id="ref-Upton2014" class="csl-entry">
Upton, Graham, and Ian Cook. 2014. <em><span class="nocase">Dictionary of Statistics</span></em>. 3rd ed. Oxford: Oxford University Press.
</div>
<div id="ref-Wardlaw1985" class="csl-entry">
Wardlaw, Alastair C. 1985. <em><span class="nocase">Practical Statistics for Experimental Biologists</span></em>. Chichester, UK: John Wiley &amp; Sons.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="9">
<li id="fn9"><p>If you are wondering why we square the difference <span class="math inline">\(x_{i} - \bar{x}\)</span> instead of just taking its absolute value, this is an excellent question! You have just invented something called the mean absolute deviation. There are some reasons why the mean absolute deviation is not as good of a measure of spread as the variance. <span class="citation">Navarro and Foxcroft (<a href="#ref-Navarro2022" role="doc-biblioref">2022</a>)</span> explain the mean absolute deviation, and how it relates to the variance, very well in <a href="https://davidfoxcroft.github.io/lsj-book/04-Descriptive-statistics.html#mean-absolute-deviation">section 4.2.3</a> of their textbook. We will not get into these points here, but it would be good to check out <span class="citation">Navarro and Foxcroft (<a href="#ref-Navarro2022" role="doc-biblioref">2022</a>)</span> for more explanation.<a href="Chapter_12.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>To get the true population variance <span class="math inline">\(\sigma^{2}\)</span>, we would also need to know the true mean <span class="math inline">\(\mu\)</span>. But we can only estimate <span class="math inline">\(\mu\)</span> from the sample, <span class="math inline">\(\bar{x}\)</span>. That is, what we would really want to calculate is <span class="math inline">\(x_{i} - \mu\)</span>, but the best we can do is <span class="math inline">\(x_{i} - \bar{x}\)</span>. The consequence of this is that there will be some error that underestimates the true distance of <span class="math inline">\(x_{i}\)</span> values from the population mean, <span class="math inline">\(\mu\)</span>. Here is the really cool part; to determine the extent to which our estimate of the variance is biased by using <span class="math inline">\(\bar{x}\)</span> instead of <span class="math inline">\(\mu\)</span>, we just need to know the expected squared difference between the two values, <span class="math inline">\((\bar{x} - \mu)^{2}\)</span>. It turns out that this difference (i.e., the bias of our estimate <span class="math inline">\(s^{2}\)</span>) is just <span class="math inline">\(\sigma^{2} / N\)</span>; that is, the true variance of the population divided by the sample size. If we subtract this value from <span class="math inline">\(\sigma^{2}\)</span>, so <span class="math inline">\(\sigma^{2} - \sigma^{2}/N\)</span>, then we can get the expected difference between the true variance and the estimate from the sample size. We can rearrange <span class="math inline">\(\sigma^{2} - \sigma^{2}/N\)</span> to get <span class="math inline">\(\sigma^{2} \times (N - 1)/N\)</span>, which means that we need to correct our sample variance by <span class="math inline">\(N / (N-1)\)</span> to get an unbiased estimate of <span class="math inline">\(\sigma^{2}\)</span>. If all of this is confusing, that is okay! This is really only relevant for those interested in statistical theory, which is not the focus of this book.<a href="Chapter_12.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>In the case of sample variance, note that we needed to use all the values <span class="math inline">\(x_{i}\)</span> in the dataset and the sample mean <span class="math inline">\(\bar{x}\)</span>. But if we know what all of the <span class="math inline">\(x_{i}\)</span> values are, then we also know <span class="math inline">\(\bar{x}\)</span>. And if we know all but one value of <span class="math inline">\(x_{i}\)</span> and <span class="math inline">\(\bar{x}\)</span>, then we could figure out the last <span class="math inline">\(x_{i}\)</span>. Hence, while we are using <span class="math inline">\(N\)</span> values in the calculation of <span class="math inline">\(s^{2}\)</span>, the use of <span class="math inline">\(\bar{x}\)</span> reduces the degree to which these values are free to vary. We have lost 1 degree of freedom in the calculation of <span class="math inline">\(\bar{x}\)</span>, so we need to account for this in our calculation of <span class="math inline">\(s^{2}\)</span> by dividing by <span class="math inline">\(N - 1\)</span>. This is another way to think about the <span class="math inline">\(N - 1\)</span> correction factor <span class="citation">(<a href="#ref-Sokal1995" role="doc-biblioref">Sokal and Rohlf 1995</a>)</span> explained in the previous footnote.<a href="Chapter_12.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>This has one caveat, which is not important for now. Values of A and B must be uncorrelated. That is, A and B cannot covary. If A and B covary, i.e., <span class="math inline">\(Cov(A, B) \neq 0\)</span>, then <span class="math inline">\(Var(A+B) = Var(A) + Var(B) + Cov(A, B)\)</span>. That is, we need to account for the covariance when calculating <span class="math inline">\(Var(A+B)\)</span>.<a href="Chapter_12.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p><a href="https://bradduthie.shinyapps.io/forest/" class="uri">https://bradduthie.shinyapps.io/forest/</a><a href="Chapter_12.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p><a href="https://bradduthie.shinyapps.io/normal_pos_neg/" class="uri">https://bradduthie.shinyapps.io/normal_pos_neg/</a><a href="Chapter_12.html#fnref14" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chapter_11.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Chapter_13.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-Summary_statistics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
